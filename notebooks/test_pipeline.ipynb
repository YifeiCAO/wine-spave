{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# æµ‹è¯•æ•°æ®ç”Ÿæˆã€è®­ç»ƒã€æµ‹è¯•æµç¨‹\n",
    "\n",
    "è¿™ä¸ªnotebookç”¨äºæµ‹è¯•æ•´ä¸ªpipelineï¼š\n",
    "1. æ•°æ®ç”Ÿæˆ\n",
    "2. æ¨¡å‹åˆ›å»º\n",
    "3. è®­ç»ƒæµç¨‹\n",
    "4. æµ‹è¯•æµç¨‹\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorchæœªå®‰è£…ï¼Œæ­£åœ¨å®‰è£…...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.3.4 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"/Users/yifei/Desktop/UCLA/wine-spave/.conda/lib/python3.11/site-packages/ipykernel_launcher.py\", line 18, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/Users/yifei/Desktop/UCLA/wine-spave/.conda/lib/python3.11/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"/Users/yifei/Desktop/UCLA/wine-spave/.conda/lib/python3.11/site-packages/ipykernel/kernelapp.py\", line 758, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/Users/yifei/Desktop/UCLA/wine-spave/.conda/lib/python3.11/site-packages/tornado/platform/asyncio.py\", line 211, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/Users/yifei/Desktop/UCLA/wine-spave/.conda/lib/python3.11/asyncio/base_events.py\", line 608, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/Users/yifei/Desktop/UCLA/wine-spave/.conda/lib/python3.11/asyncio/base_events.py\", line 1936, in _run_once\n",
      "    handle._run()\n",
      "  File \"/Users/yifei/Desktop/UCLA/wine-spave/.conda/lib/python3.11/asyncio/events.py\", line 84, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"/Users/yifei/Desktop/UCLA/wine-spave/.conda/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 614, in shell_main\n",
      "    await self.dispatch_shell(msg, subshell_id=subshell_id)\n",
      "  File \"/Users/yifei/Desktop/UCLA/wine-spave/.conda/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 471, in dispatch_shell\n",
      "    await result\n",
      "  File \"/Users/yifei/Desktop/UCLA/wine-spave/.conda/lib/python3.11/site-packages/ipykernel/ipkernel.py\", line 366, in execute_request\n",
      "    await super().execute_request(stream, ident, parent)\n",
      "  File \"/Users/yifei/Desktop/UCLA/wine-spave/.conda/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 827, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"/Users/yifei/Desktop/UCLA/wine-spave/.conda/lib/python3.11/site-packages/ipykernel/ipkernel.py\", line 458, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"/Users/yifei/Desktop/UCLA/wine-spave/.conda/lib/python3.11/site-packages/ipykernel/zmqshell.py\", line 663, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"/Users/yifei/Desktop/UCLA/wine-spave/.conda/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3116, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"/Users/yifei/Desktop/UCLA/wine-spave/.conda/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3171, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"/Users/yifei/Desktop/UCLA/wine-spave/.conda/lib/python3.11/site-packages/IPython/core/async_helpers.py\", line 128, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"/Users/yifei/Desktop/UCLA/wine-spave/.conda/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3394, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"/Users/yifei/Desktop/UCLA/wine-spave/.conda/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3639, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"/Users/yifei/Desktop/UCLA/wine-spave/.conda/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3699, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/var/folders/32/4892nkzn7nd8j23hmv15vz4c0000gn/T/ipykernel_9247/1269412152.py\", line 13, in <module>\n",
      "    import torch\n",
      "  File \"/Users/yifei/Desktop/UCLA/wine-spave/.conda/lib/python3.11/site-packages/torch/__init__.py\", line 1477, in <module>\n",
      "    from .functional import *  # noqa: F403\n",
      "  File \"/Users/yifei/Desktop/UCLA/wine-spave/.conda/lib/python3.11/site-packages/torch/functional.py\", line 9, in <module>\n",
      "    import torch.nn.functional as F\n",
      "  File \"/Users/yifei/Desktop/UCLA/wine-spave/.conda/lib/python3.11/site-packages/torch/nn/__init__.py\", line 1, in <module>\n",
      "    from .modules import *  # noqa: F403\n",
      "  File \"/Users/yifei/Desktop/UCLA/wine-spave/.conda/lib/python3.11/site-packages/torch/nn/modules/__init__.py\", line 35, in <module>\n",
      "    from .transformer import TransformerEncoder, TransformerDecoder, \\\n",
      "  File \"/Users/yifei/Desktop/UCLA/wine-spave/.conda/lib/python3.11/site-packages/torch/nn/modules/transformer.py\", line 20, in <module>\n",
      "    device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n",
      "/Users/yifei/Desktop/UCLA/wine-spave/.conda/lib/python3.11/site-packages/torch/nn/modules/transformer.py:20: UserWarning: Failed to initialize NumPy: _ARRAY_API not found (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/utils/tensor_numpy.cpp:84.)\n",
      "  device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ PyTorchå®‰è£…å®Œæˆ\n",
      "\n",
      "å¯¼å…¥åŸºç¡€åº“...\n",
      "å¯¼å…¥é¡¹ç›®æ¨¡å—...\n",
      "\n",
      "âœ“ åŸºç¡€å¯¼å…¥å®Œæˆï¼\n",
      "é¡¹ç›®æ ¹ç›®å½•: /Users/yifei/Desktop/UCLA/wine-spave\n",
      "æ³¨æ„: trainå’Œtestå‡½æ•°ä¼šåœ¨éœ€è¦æ—¶å¯¼å…¥ï¼ˆå› ä¸ºå®ƒä»¬ä¾èµ–analyzeæ¨¡å—ï¼Œå¯¼å…¥è¾ƒæ…¢ï¼‰\n"
     ]
    }
   ],
   "source": [
    "# å¯¼å…¥å¿…è¦çš„åº“\n",
    "import sys\n",
    "import os\n",
    "import subprocess\n",
    "\n",
    "# æ£€æŸ¥å¹¶å®‰è£…numpyï¼ˆå…¼å®¹ç‰ˆæœ¬ï¼‰\n",
    "try:\n",
    "    import numpy as np\n",
    "    numpy_version = np.__version__\n",
    "    print(f\"âœ“ NumPyå·²å®‰è£… (ç‰ˆæœ¬: {numpy_version})\")\n",
    "    # æ£€æŸ¥æ˜¯å¦æ˜¯NumPy 2.xï¼Œå¦‚æœæ˜¯åˆ™é™çº§\n",
    "    if numpy_version.startswith('2.'):\n",
    "        print(\"æ£€æµ‹åˆ°NumPy 2.xï¼Œé™çº§åˆ°NumPy 1.xä»¥å…¼å®¹å…¶ä»–æ¨¡å—...\")\n",
    "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", \"numpy<2\"])\n",
    "        import importlib\n",
    "        importlib.reload(sys.modules.get('numpy', None))\n",
    "        import numpy as np\n",
    "        print(f\"âœ“ NumPyå·²é™çº§åˆ°ç‰ˆæœ¬: {np.__version__}\")\n",
    "except ImportError:\n",
    "    print(\"NumPyæœªå®‰è£…ï¼Œæ­£åœ¨å®‰è£…å…¼å®¹ç‰ˆæœ¬...\")\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", \"numpy<2\"])\n",
    "    import numpy as np\n",
    "    print(f\"âœ“ NumPyå®‰è£…å®Œæˆ (ç‰ˆæœ¬: {np.__version__})\")\n",
    "\n",
    "# æ£€æŸ¥å¹¶å®‰è£…PyTorchï¼ˆå¦‚æœéœ€è¦ï¼‰\n",
    "try:\n",
    "    import torch\n",
    "    print(\"âœ“ PyTorchå·²å®‰è£…\")\n",
    "except ImportError:\n",
    "    print(\"PyTorchæœªå®‰è£…ï¼Œæ­£åœ¨å®‰è£…...\")\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", \"torch\", \"torchvision\"])\n",
    "    import torch\n",
    "    print(\"âœ“ PyTorchå®‰è£…å®Œæˆ\")\n",
    "\n",
    "# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„ï¼ˆnotebookåœ¨notebooks/ç›®å½•ä¸‹ï¼‰\n",
    "current_dir = os.getcwd()\n",
    "if 'notebooks' in current_dir:\n",
    "    project_root = os.path.dirname(current_dir)\n",
    "else:\n",
    "    project_root = current_dir\n",
    "\n",
    "if project_root not in sys.path:\n",
    "    sys.path.insert(0, project_root)\n",
    "\n",
    "print(\"\\nå¯¼å…¥åŸºç¡€åº“...\")\n",
    "import torch.nn as nn\n",
    "import random\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "print(\"å¯¼å…¥é¡¹ç›®æ¨¡å—...\")\n",
    "# å…ˆå¯¼å…¥åŸºç¡€æ¨¡å—ï¼ˆè¿™äº›å¯¼å…¥å¾ˆå¿«ï¼‰\n",
    "from data import get_loaders, GridDataGenerator, GridDataset, grid_collate\n",
    "from models import get_model\n",
    "\n",
    "# å»¶è¿Ÿå¯¼å…¥trainå’Œtestï¼ˆå› ä¸ºå®ƒä»¬ä¼šå¯¼å…¥analyzeï¼Œè€Œanalyzeå¯¼å…¥å¾ˆé‡çš„åº“ï¼‰\n",
    "# æˆ‘ä»¬ä¼šåœ¨éœ€è¦æ—¶æ‰å¯¼å…¥å®ƒä»¬\n",
    "\n",
    "print(\"\\nâœ“ åŸºç¡€å¯¼å…¥å®Œæˆï¼\")\n",
    "print(f\"é¡¹ç›®æ ¹ç›®å½•: {project_root}\")\n",
    "print(\"æ³¨æ„: trainå’Œtestå‡½æ•°ä¼šåœ¨éœ€è¦æ—¶å¯¼å…¥ï¼ˆå› ä¸ºå®ƒä»¬ä¾èµ–analyzeæ¨¡å—ï¼Œå¯¼å…¥è¾ƒæ…¢ï¼‰\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. è®¾ç½®å‚æ•°\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "å‚æ•°è®¾ç½®å®Œæˆï¼\n",
      "æ¨¡å‹: rnn\n",
      "è®­ç»ƒæ­¥æ•°: 100\n",
      "Batch size: 16\n"
     ]
    }
   ],
   "source": [
    "# åˆ›å»ºä¸€ä¸ªç®€å•çš„å‚æ•°ç±»\n",
    "class Args:\n",
    "    def __init__(self):\n",
    "        # è®¾å¤‡è®¾ç½®\n",
    "        self.use_cuda = False\n",
    "        self.device = \"cpu\"\n",
    "        self.seed = 0\n",
    "        \n",
    "        # æ•°æ®é›†è®¾ç½®\n",
    "        self.use_images = False  # ä½¿ç”¨ç´¢å¼•è€Œä¸æ˜¯å›¾åƒ\n",
    "        self.image_dir = 'images/faces16'\n",
    "        self.training_regime = 'ungrouped'  # ä½¿ç”¨ungroupedæ¨¡å¼ï¼Œæ›´ç®€å•\n",
    "        self.grid_size = 4\n",
    "        self.ctx_order = 'first'\n",
    "        self.inner_4x4 = False\n",
    "        \n",
    "        # è®­ç»ƒè®¾ç½®\n",
    "        self.bs = 16  # è¾ƒå°çš„batch sizeç”¨äºæµ‹è¯•\n",
    "        self.lr = 0.001\n",
    "        self.n_steps = 100  # å°‘é‡æ­¥æ•°ç”¨äºæµ‹è¯•\n",
    "        self.print_every = 10\n",
    "        self.test_every = 25\n",
    "        self.analyze_every = 50\n",
    "        \n",
    "        # æ¨¡å‹è®¾ç½®\n",
    "        self.model_name = 'rnn'\n",
    "        self.ctx_scale = 1.0\n",
    "        self.measure_grad_norm = False\n",
    "        \n",
    "        # åˆ†æè®¾ç½®\n",
    "        self.dim_red_method = 'pca'\n",
    "\n",
    "# åˆ›å»ºå‚æ•°å¯¹è±¡\n",
    "args = Args()\n",
    "\n",
    "# è®¾ç½®éšæœºç§å­\n",
    "torch.manual_seed(args.seed)\n",
    "random.seed(args.seed)\n",
    "np.random.seed(args.seed)\n",
    "\n",
    "print(\"å‚æ•°è®¾ç½®å®Œæˆï¼\")\n",
    "print(f\"æ¨¡å‹: {args.model_name}\")\n",
    "print(f\"è®­ç»ƒæ­¥æ•°: {args.n_steps}\")\n",
    "print(f\"Batch size: {args.bs}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. æµ‹è¯•æ•°æ®ç”Ÿæˆ\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ç”Ÿæˆæ•°æ®...\n",
      "è®­ç»ƒæ ·æœ¬æ•°: 192\n",
      "æµ‹è¯•æ ·æœ¬æ•°: 192\n",
      "åˆ†ææ ·æœ¬æ•°: 384\n",
      "\n",
      "ç¤ºä¾‹æ ·æœ¬:\n",
      "  ä¸Šä¸‹æ–‡: 1\n",
      "  ä½ç½®1: (0, 0), ä½ç½®2: (0, 1)\n",
      "  æ ‡ç­¾: 0\n",
      "  ä¿¡æ¯: {'loc1': (0, 0), 'loc2': (0, 1), 'idx1': 0, 'idx2': 1, 'cong': 0}\n"
     ]
    }
   ],
   "source": [
    "# æµ‹è¯•æ•°æ®ç”Ÿæˆå™¨\n",
    "print(\"ç”Ÿæˆæ•°æ®...\")\n",
    "grid = GridDataGenerator(\n",
    "    training_regime=args.training_regime,\n",
    "    size=args.grid_size,\n",
    "    use_images=args.use_images,\n",
    "    image_dir=args.image_dir,\n",
    "    inner_4x4=args.inner_4x4\n",
    ")\n",
    "\n",
    "print(f\"è®­ç»ƒæ ·æœ¬æ•°: {len(grid.train)}\")\n",
    "print(f\"æµ‹è¯•æ ·æœ¬æ•°: {len(grid.test)}\")\n",
    "print(f\"åˆ†ææ ·æœ¬æ•°: {len(grid.analyze)}\")\n",
    "\n",
    "# æŸ¥çœ‹ä¸€ä¸ªæ ·æœ¬\n",
    "sample = grid.train[0]\n",
    "ctx, loc1, loc2, y, info = sample\n",
    "print(f\"\\nç¤ºä¾‹æ ·æœ¬:\")\n",
    "print(f\"  ä¸Šä¸‹æ–‡: {ctx}\")\n",
    "print(f\"  ä½ç½®1: {loc1}, ä½ç½®2: {loc2}\")\n",
    "print(f\"  æ ‡ç­¾: {y}\")\n",
    "print(f\"  ä¿¡æ¯: {info}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batchå½¢çŠ¶:\n",
      "  ä¸Šä¸‹æ–‡: torch.Size([16])\n",
      "  è‘¡è„é…’1: torch.Size([16])\n",
      "  è‘¡è„é…’2: torch.Size([16])\n",
      "  æ ‡ç­¾: torch.Size([16])\n",
      "  ä¿¡æ¯é”®: dict_keys(['loc1', 'loc2', 'idx1', 'idx2', 'cong'])\n"
     ]
    }
   ],
   "source": [
    "# åˆ›å»ºæ•°æ®é›†å’Œæ•°æ®åŠ è½½å™¨\n",
    "train_set = GridDataset(grid.train, grid.loc2idx, grid.idx2tensor)\n",
    "test_set = GridDataset(grid.test, grid.loc2idx, grid.idx2tensor)\n",
    "\n",
    "train_loader = DataLoader(train_set, batch_size=args.bs, shuffle=True, \n",
    "                          collate_fn=grid_collate)\n",
    "test_loader = DataLoader(test_set, batch_size=args.bs, shuffle=False,\n",
    "                         collate_fn=grid_collate)\n",
    "\n",
    "# æµ‹è¯•ä¸€ä¸ªbatch\n",
    "batch = next(iter(train_loader))\n",
    "ctx, f1, f2, y, info = batch\n",
    "print(f\"Batchå½¢çŠ¶:\")\n",
    "print(f\"  ä¸Šä¸‹æ–‡: {ctx.shape}\")\n",
    "print(f\"  è‘¡è„é…’1: {f1.shape}\")\n",
    "print(f\"  è‘¡è„é…’2: {f2.shape}\")\n",
    "print(f\"  æ ‡ç­¾: {y.shape}\")\n",
    "print(f\"  ä¿¡æ¯é”®: {info.keys()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. æµ‹è¯•æ¨¡å‹åˆ›å»º\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "åˆ›å»ºæ¨¡å‹...\n",
      "Model is an LSTM\n",
      "\n",
      "æ¨¡å‹: rnn\n",
      "å‚æ•°æ•°é‡: 83778\n",
      "\n",
      "å‰å‘ä¼ æ’­æµ‹è¯•:\n",
      "  è¾“å…¥å½¢çŠ¶: ctx=torch.Size([4]), f1=torch.Size([4]), f2=torch.Size([4])\n",
      "  è¾“å‡ºå½¢çŠ¶: torch.Size([4, 2])\n",
      "  è¡¨ç¤ºå½¢çŠ¶: [('hidden_f1', torch.Size([4, 128])), ('hidden_f2', torch.Size([4, 128]))]\n",
      "  é¢„æµ‹: tensor([1, 1, 1, 1])\n",
      "  çœŸå®æ ‡ç­¾: tensor([1, 1, 0, 1])\n"
     ]
    }
   ],
   "source": [
    "# åˆ›å»ºæ¨¡å‹\n",
    "print(\"åˆ›å»ºæ¨¡å‹...\")\n",
    "model = get_model(args)\n",
    "model.to(args.device)\n",
    "\n",
    "# æ‰“å°æ¨¡å‹ç»“æ„\n",
    "print(f\"\\næ¨¡å‹: {args.model_name}\")\n",
    "print(f\"å‚æ•°æ•°é‡: {sum(p.numel() for p in model.parameters())}\")\n",
    "\n",
    "# æµ‹è¯•å‰å‘ä¼ æ’­\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    test_ctx = ctx[:4].to(args.device)\n",
    "    test_f1 = f1[:4].to(args.device)\n",
    "    test_f2 = f2[:4].to(args.device)\n",
    "    \n",
    "    y_hat, reps = model(test_ctx, test_f1, test_f2)\n",
    "    print(f\"\\nå‰å‘ä¼ æ’­æµ‹è¯•:\")\n",
    "    print(f\"  è¾“å…¥å½¢çŠ¶: ctx={test_ctx.shape}, f1={test_f1.shape}, f2={test_f2.shape}\")\n",
    "    print(f\"  è¾“å‡ºå½¢çŠ¶: {y_hat.shape}\")\n",
    "    print(f\"  è¡¨ç¤ºå½¢çŠ¶: {[(k, v.shape) for k, v in reps.items()]}\")\n",
    "    print(f\"  é¢„æµ‹: {torch.argmax(y_hat, dim=1)}\")\n",
    "    print(f\"  çœŸå®æ ‡ç­¾: {y[:4]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. æµ‹è¯•è®­ç»ƒæµç¨‹\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model is an LSTM\n",
      "å¼€å§‹è®­ç»ƒ...\n",
      "è®­ç»ƒæ•°æ®batchesæ•°: 12\n",
      "ç›®æ ‡è®­ç»ƒæ­¥æ•°: 100\n",
      "\n",
      "Step 10/100, Loss: 0.6950\n",
      "Step 20/100, Loss: 0.6917\n",
      "Step 30/100, Loss: 0.6910\n",
      "Step 40/100, Loss: 0.6913\n",
      "Step 50/100, Loss: 0.6884\n",
      "Step 60/100, Loss: 0.6859\n",
      "Step 70/100, Loss: 0.6778\n",
      "Step 80/100, Loss: 0.6671\n",
      "Step 90/100, Loss: 0.6329\n",
      "Step 100/100, Loss: 0.5901\n",
      "\n",
      "è®­ç»ƒå®Œæˆï¼\n",
      "  æ€»æ­¥æ•°: 100\n",
      "  å¹³å‡æŸå¤±: 0.6711\n",
      "  æœ€ç»ˆæŸå¤±: 0.5857\n"
     ]
    }
   ],
   "source": [
    "# ä½¿ç”¨get_loadersè·å–æ•°æ®ï¼ˆè¿™æ ·ä¼šè®¾ç½®argsä¸­çš„ä¸€äº›å±æ€§ï¼‰\n",
    "data = get_loaders(args)\n",
    "train_loader, test_loader, analyze_loader = data\n",
    "\n",
    "# åˆ›å»ºæ–°æ¨¡å‹ç”¨äºè®­ç»ƒ\n",
    "model = get_model(args)\n",
    "model.to(args.device)\n",
    "\n",
    "# è®¾ç½®ä¼˜åŒ–å™¨å’ŒæŸå¤±å‡½æ•°\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=args.lr)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "print(\"å¼€å§‹è®­ç»ƒ...\")\n",
    "print(f\"è®­ç»ƒæ•°æ®batchesæ•°: {len(train_loader)}\")\n",
    "print(f\"ç›®æ ‡è®­ç»ƒæ­¥æ•°: {args.n_steps}\\n\")\n",
    "\n",
    "model.train()\n",
    "\n",
    "losses = []\n",
    "step = 0\n",
    "# ä½¿ç”¨itertools.cycleæ¥å¾ªç¯ä½¿ç”¨æ•°æ®ï¼Œç›´åˆ°è¾¾åˆ°n_steps\n",
    "from itertools import cycle\n",
    "\n",
    "# åˆ›å»ºå¾ªç¯è¿­ä»£å™¨\n",
    "train_iter = cycle(train_loader)\n",
    "\n",
    "while step < args.n_steps:\n",
    "    batch = next(train_iter)\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    ctx, f1, f2, y, info = batch\n",
    "    ctx = ctx.to(args.device)\n",
    "    f1 = f1.to(args.device)\n",
    "    f2 = f2.to(args.device)\n",
    "    y = y.to(args.device)\n",
    "    \n",
    "    # å‰å‘ä¼ æ’­\n",
    "    y_hat, _ = model(ctx, f1, f2)\n",
    "    loss = loss_fn(y_hat, y)\n",
    "    \n",
    "    # åå‘ä¼ æ’­\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    losses.append(loss.item())\n",
    "    step += 1\n",
    "    \n",
    "    if step % args.print_every == 0:\n",
    "        avg_loss = np.mean(losses[-args.print_every:])\n",
    "        print(f\"Step {step}/{args.n_steps}, Loss: {avg_loss:.4f}\")\n",
    "\n",
    "print(f\"\\nè®­ç»ƒå®Œæˆï¼\")\n",
    "print(f\"  æ€»æ­¥æ•°: {step}\")\n",
    "print(f\"  å¹³å‡æŸå¤±: {np.mean(losses):.4f}\")\n",
    "print(f\"  æœ€ç»ˆæŸå¤±: {losses[-1]:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. æµ‹è¯•æ¨¡å‹ - åˆ†æè¯´æ˜\n",
    "\n",
    "`test.py` å‡½æ•°ä¼šè¿›è¡Œä»¥ä¸‹5ç§åˆ†æï¼š\n",
    "\n",
    "### 1. æ€»ä½“å‡†ç¡®ç‡ (acc)\n",
    "- æ‰€æœ‰æµ‹è¯•æ ·æœ¬çš„å¹³å‡å‡†ç¡®ç‡\n",
    "- è¡¡é‡æ¨¡å‹çš„æ•´ä½“æ€§èƒ½\n",
    "\n",
    "### 2. ä¸€è‡´å‡†ç¡®ç‡ (cong_acc) vs ä¸ä¸€è‡´å‡†ç¡®ç‡ (incong_acc)\n",
    "\n",
    "**ä¸€è‡´æ ·æœ¬ (congruent, cong=1)**ï¼š\n",
    "- ä¸¤ä¸ªç»´åº¦æ–¹å‘ç›¸åŒ\n",
    "- ä¾‹å¦‚ï¼šè‘¡è„é…’Aåœ¨Tasteå’ŒBodyä¸Šéƒ½æ¯”Bé«˜ï¼Œæˆ–éƒ½æ›´ä½\n",
    "- æ›´å®¹æ˜“åˆ¤æ–­ï¼Œå› ä¸ºä¸¤ä¸ªç»´åº¦æŒ‡å‘åŒä¸€æ–¹å‘\n",
    "\n",
    "**ä¸ä¸€è‡´æ ·æœ¬ (incongruent, cong=-1)**ï¼š\n",
    "- ä¸¤ä¸ªç»´åº¦æ–¹å‘ç›¸å\n",
    "- ä¾‹å¦‚ï¼šè‘¡è„é…’Aåœ¨Tasteä¸Šæ¯”Bé«˜ï¼Œä½†åœ¨Bodyä¸Šæ¯”Bä½\n",
    "- æ›´éš¾åˆ¤æ–­ï¼Œéœ€è¦æ ¹æ®å½“å‰ä¸Šä¸‹æ–‡é€‰æ‹©æ­£ç¡®çš„ç»´åº¦è¿›è¡Œæ¯”è¾ƒ\n",
    "\n",
    "**ä¸­æ€§æ ·æœ¬ (cong=0)**ï¼š\n",
    "- ä¸¤ä¸ªè‘¡è„é…’åœ¨æŸä¸ªç»´åº¦ä¸Šç›¸åŒï¼ˆx1==x2æˆ–y1==y2ï¼‰\n",
    "- ä¸å‚ä¸ä¸€è‡´/ä¸ä¸€è‡´çš„ç»Ÿè®¡\n",
    "\n",
    "### 3. å„ç­‰çº§å‡†ç¡®ç‡\n",
    "- æŒ‰ç¬¬ä¸€ä¸ªè‘¡è„é…’åœ¨æ¯ä¸ªç»´åº¦ä¸­çš„ç­‰çº§ï¼ˆ0-3ï¼‰åˆ†åˆ«ç»Ÿè®¡å‡†ç¡®ç‡\n",
    "- ç”¨äºæ£€æŸ¥æ¨¡å‹åœ¨ä¸åŒç­‰çº§ä¸Šçš„è¡¨ç°æ˜¯å¦ä¸€è‡´\n",
    "- å¯ä»¥å‘ç°æ¨¡å‹æ˜¯å¦å­˜åœ¨ç­‰çº§åå·®\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. æµ‹è¯•æµ‹è¯•æµç¨‹\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ç»“æœåˆ†æ\n",
    "\n",
    "æ ¹æ®ä½ çš„æµ‹è¯•ç»“æœï¼Œæˆ‘ä»¬å¯ä»¥è¿›è¡Œä¸€äº›åˆ†æï¼š\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# åˆ†ææµ‹è¯•ç»“æœ\n",
    "print(\"ğŸ“Š æµ‹è¯•ç»“æœåˆ†æ:\\n\")\n",
    "\n",
    "# è®¡ç®—ä¸€è‡´å’Œä¸ä¸€è‡´æ ·æœ¬çš„éš¾åº¦å·®å¼‚\n",
    "difficulty_gap = test_results['cong_acc'] - test_results['incong_acc']\n",
    "print(f\"1. éš¾åº¦å·®å¼‚åˆ†æ:\")\n",
    "print(f\"   ä¸€è‡´å‡†ç¡®ç‡: {test_results['cong_acc']:.4f} (100%)\")\n",
    "print(f\"   ä¸ä¸€è‡´å‡†ç¡®ç‡: {test_results['incong_acc']:.4f} ({test_results['incong_acc']*100:.2f}%)\")\n",
    "print(f\"   éš¾åº¦å·®å¼‚: {difficulty_gap:.4f} ({difficulty_gap*100:.2f}ä¸ªç™¾åˆ†ç‚¹)\")\n",
    "print(f\"   âœ“ è¿™ä¸ªå·®å¼‚æ˜¯åˆç†çš„ï¼Œå› ä¸ºä¸ä¸€è‡´æ ·æœ¬éœ€è¦æ ¹æ®ä¸Šä¸‹æ–‡é€‰æ‹©æ­£ç¡®çš„ç»´åº¦\")\n",
    "\n",
    "print(f\"\\n2. æ€§èƒ½è¯„ä¼°:\")\n",
    "if test_results['acc'] > 0.85:\n",
    "    print(f\"   âœ“ æ€»ä½“å‡†ç¡®ç‡ {test_results['acc']:.4f} è¡¨ç°ä¼˜ç§€ï¼ˆ>85%ï¼‰\")\n",
    "elif test_results['acc'] > 0.70:\n",
    "    print(f\"   âš  æ€»ä½“å‡†ç¡®ç‡ {test_results['acc']:.4f} è¡¨ç°è‰¯å¥½ï¼ˆ>70%ï¼‰\")\n",
    "else:\n",
    "    print(f\"   âœ— æ€»ä½“å‡†ç¡®ç‡ {test_results['acc']:.4f} éœ€è¦æ”¹è¿›ï¼ˆ<70%ï¼‰\")\n",
    "\n",
    "if test_results['incong_acc'] > 0.60:\n",
    "    print(f\"   âœ“ ä¸ä¸€è‡´å‡†ç¡®ç‡ {test_results['incong_acc']:.4f} é«˜äºéšæœºçŒœæµ‹ï¼ˆ50%ï¼‰\")\n",
    "    print(f\"   âœ“ è¯´æ˜æ¨¡å‹èƒ½å¤Ÿæ ¹æ®ä¸Šä¸‹æ–‡é€‰æ‹©æ­£ç¡®çš„ç»´åº¦\")\n",
    "else:\n",
    "    print(f\"   âš  ä¸ä¸€è‡´å‡†ç¡®ç‡ {test_results['incong_acc']:.4f} æ¥è¿‘éšæœºçŒœæµ‹\")\n",
    "    print(f\"   âš  æ¨¡å‹åœ¨æ ¹æ®ä¸Šä¸‹æ–‡é€‰æ‹©ç»´åº¦æ–¹é¢éœ€è¦æ”¹è¿›\")\n",
    "\n",
    "print(f\"\\n3. æ¨¡å‹å­¦ä¹ æƒ…å†µ:\")\n",
    "print(f\"   - æ¨¡å‹å¯¹ä¸€è‡´æ ·æœ¬å­¦ä¹ å®Œç¾ï¼ˆ100%å‡†ç¡®ç‡ï¼‰\")\n",
    "print(f\"   - æ¨¡å‹å¯¹ä¸ä¸€è‡´æ ·æœ¬æœ‰ä¸€å®šå­¦ä¹ ï¼ˆ{test_results['incong_acc']*100:.2f}%å‡†ç¡®ç‡ï¼‰\")\n",
    "print(f\"   - ä¸ä¸€è‡´æ ·æœ¬æ›´éš¾ï¼Œå› ä¸ºéœ€è¦è®¤çŸ¥æ§åˆ¶ï¼ˆæ ¹æ®ä¸Šä¸‹æ–‡é€‰æ‹©ç»´åº¦ï¼‰\")\n",
    "print(f\"   - è¿™ä¸ªç»“æœæ¨¡å¼ç¬¦åˆè®¤çŸ¥æ§åˆ¶ä»»åŠ¡çš„é¢„æœŸ\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# å¯è§†åŒ–å‡†ç¡®ç‡å¯¹æ¯”\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(8, 6))\n",
    "\n",
    "categories = ['æ€»ä½“', 'ä¸€è‡´æ ·æœ¬', 'ä¸ä¸€è‡´æ ·æœ¬']\n",
    "accuracies = [\n",
    "    test_results['acc'],\n",
    "    test_results['cong_acc'],\n",
    "    test_results['incong_acc']\n",
    "]\n",
    "colors = ['#2ecc71', '#3498db', '#e74c3c']\n",
    "\n",
    "bars = ax.bar(categories, accuracies, color=colors, alpha=0.7, edgecolor='black', linewidth=1.5)\n",
    "\n",
    "# æ·»åŠ æ•°å€¼æ ‡ç­¾\n",
    "for bar, acc in zip(bars, accuracies):\n",
    "    height = bar.get_height()\n",
    "    ax.text(bar.get_x() + bar.get_width()/2., height,\n",
    "            f'{acc:.4f}\\n({acc*100:.2f}%)',\n",
    "            ha='center', va='bottom', fontsize=11, fontweight='bold')\n",
    "\n",
    "# æ·»åŠ éšæœºçŒœæµ‹åŸºå‡†çº¿\n",
    "ax.axhline(y=0.5, color='gray', linestyle='--', linewidth=1, label='éšæœºçŒœæµ‹ (50%)')\n",
    "ax.axhline(y=1.0, color='green', linestyle='--', linewidth=1, alpha=0.3, label='å®Œç¾ (100%)')\n",
    "\n",
    "ax.set_ylabel('å‡†ç¡®ç‡', fontsize=12, fontweight='bold')\n",
    "ax.set_title('æ¨¡å‹æµ‹è¯•ç»“æœå¯¹æ¯”', fontsize=14, fontweight='bold')\n",
    "ax.set_ylim([0, 1.1])\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"âœ“ å¯è§†åŒ–å®Œæˆ\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ NumPyåœ¨PyTorchä¸­ä¸å¯ç”¨: Numpy is not available\n",
      "å°†ä½¿ç”¨çº¯PyTorchå®ç°æµ‹è¯•å‡½æ•°...\n",
      "ä½¿ç”¨çº¯PyTorchæµ‹è¯•å‡½æ•°...\n",
      "\n",
      "æµ‹è¯•ç»“æœ:\n",
      "  æ€»ä½“å‡†ç¡®ç‡: 0.8802\n",
      "  ä¸€è‡´å‡†ç¡®ç‡: 1.0000\n",
      "  ä¸ä¸€è‡´å‡†ç¡®ç‡: 0.6806\n",
      "\n",
      "ä¸Šä¸‹æ–‡0å„ç­‰çº§å‡†ç¡®ç‡ (Context 0 - ä¾‹å¦‚: Tasteç»´åº¦):\n",
      "  è¯´æ˜: å½“ç¬¬ä¸€ä¸ªè‘¡è„é…’åœ¨ä¸Šä¸‹æ–‡0ä¸­çš„ç­‰çº§ä¸º0/1/2/3æ—¶ï¼Œæ¨¡å‹çš„å‡†ç¡®ç‡\n",
      "    ç­‰çº§ 0: 1.0000\n",
      "    ç­‰çº§ 1: 0.8125\n",
      "    ç­‰çº§ 2: 0.7500\n",
      "    ç­‰çº§ 3: 0.8750\n",
      "\n",
      "ä¸Šä¸‹æ–‡1å„ç­‰çº§å‡†ç¡®ç‡ (Context 1 - ä¾‹å¦‚: Bodyç»´åº¦):\n",
      "  è¯´æ˜: å½“ç¬¬ä¸€ä¸ªè‘¡è„é…’åœ¨ä¸Šä¸‹æ–‡1ä¸­çš„ç­‰çº§ä¸º0/1/2/3æ—¶ï¼Œæ¨¡å‹çš„å‡†ç¡®ç‡\n",
      "    ç­‰çº§ 0: 0.9375\n",
      "    ç­‰çº§ 1: 0.8125\n",
      "    ç­‰çº§ 2: 0.8125\n",
      "    ç­‰çº§ 3: 0.8750\n",
      "\n",
      "ğŸ“ test.py åˆ†æå†…å®¹è¯¦è§£:\n",
      "\n",
      "1. æ€»ä½“å‡†ç¡®ç‡ (acc):\n",
      "   - æ‰€æœ‰æµ‹è¯•æ ·æœ¬çš„å¹³å‡å‡†ç¡®ç‡\n",
      "   - è¡¡é‡æ¨¡å‹çš„æ•´ä½“æ€§èƒ½\n",
      "\n",
      "2. ä¸€è‡´å‡†ç¡®ç‡ (cong_acc):\n",
      "   - åªç»Ÿè®¡'ä¸€è‡´'æ ·æœ¬çš„å‡†ç¡®ç‡\n",
      "   - 'ä¸€è‡´'æŒ‡ï¼šä¸¤ä¸ªç»´åº¦æ–¹å‘ç›¸åŒï¼ˆå¦‚éƒ½æ›´é«˜æˆ–éƒ½æ›´ä½ï¼‰\n",
      "   - ä¾‹å¦‚ï¼šè‘¡è„é…’Aåœ¨Tasteå’ŒBodyä¸Šéƒ½æ¯”Bé«˜\n",
      "\n",
      "3. ä¸ä¸€è‡´å‡†ç¡®ç‡ (incong_acc):\n",
      "   - åªç»Ÿè®¡'ä¸ä¸€è‡´'æ ·æœ¬çš„å‡†ç¡®ç‡\n",
      "   - 'ä¸ä¸€è‡´'æŒ‡ï¼šä¸¤ä¸ªç»´åº¦æ–¹å‘ç›¸åï¼ˆä¸€ä¸ªæ›´é«˜ï¼Œå¦ä¸€ä¸ªæ›´ä½ï¼‰\n",
      "   - ä¾‹å¦‚ï¼šè‘¡è„é…’Aåœ¨Tasteä¸Šæ¯”Bé«˜ï¼Œä½†åœ¨Bodyä¸Šæ¯”Bä½\n",
      "   - ä¸ä¸€è‡´æ ·æœ¬æ›´éš¾ï¼Œå› ä¸ºéœ€è¦æ ¹æ®ä¸Šä¸‹æ–‡é€‰æ‹©æ­£ç¡®çš„ç»´åº¦\n",
      "\n",
      "4. ä¸Šä¸‹æ–‡0å„ç­‰çº§å‡†ç¡®ç‡ (loc1_ctx0_acc):\n",
      "   - æŒ‰ç¬¬ä¸€ä¸ªè‘¡è„é…’åœ¨ä¸Šä¸‹æ–‡0ä¸­çš„ç­‰çº§ï¼ˆ0-3ï¼‰åˆ†ç±»ç»Ÿè®¡\n",
      "   - æ£€æŸ¥æ¨¡å‹åœ¨ä¸åŒç­‰çº§ä¸Šçš„è¡¨ç°æ˜¯å¦ä¸€è‡´\n",
      "\n",
      "5. ä¸Šä¸‹æ–‡1å„ç­‰çº§å‡†ç¡®ç‡ (loc1_ctx1_acc):\n",
      "   - æŒ‰ç¬¬ä¸€ä¸ªè‘¡è„é…’åœ¨ä¸Šä¸‹æ–‡1ä¸­çš„ç­‰çº§ï¼ˆ0-3ï¼‰åˆ†ç±»ç»Ÿè®¡\n",
      "   - æ£€æŸ¥æ¨¡å‹åœ¨ä¸åŒç­‰çº§ä¸Šçš„è¡¨ç°æ˜¯å¦ä¸€è‡´\n",
      "\n",
      "ğŸ’¡ åˆ†ææ„ä¹‰:\n",
      "  - å¦‚æœcong_acc > incong_acc: è¯´æ˜æ¨¡å‹å¯¹ä¸€è‡´æ ·æœ¬å­¦ä¹ æ›´å¥½\n",
      "  - å¦‚æœæŸäº›ç­‰çº§å‡†ç¡®ç‡ä½: è¯´æ˜æ¨¡å‹åœ¨è¯¥ç­‰çº§ä¸Šå­¦ä¹ ä¸è¶³\n",
      "  - å¦‚æœä¸¤ä¸ªä¸Šä¸‹æ–‡è¡¨ç°å·®å¼‚å¤§: è¯´æ˜æ¨¡å‹å¯¹æŸä¸ªç»´åº¦å­¦ä¹ æ›´å¥½\n"
     ]
    }
   ],
   "source": [
    "# æµ‹è¯•æ¨¡å‹\n",
    "# æ£€æŸ¥numpyæ˜¯å¦åœ¨PyTorchä¸­å¯ç”¨\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "# æµ‹è¯•numpyè½¬æ¢\n",
    "test_tensor = torch.tensor([1, 2, 3])\n",
    "try:\n",
    "    test_numpy = test_tensor.cpu().numpy()\n",
    "    numpy_available = True\n",
    "    print(\"âœ“ NumPyåœ¨PyTorchä¸­å¯ç”¨\")\n",
    "except RuntimeError as e:\n",
    "    numpy_available = False\n",
    "    print(f\"âš ï¸ NumPyåœ¨PyTorchä¸­ä¸å¯ç”¨: {e}\")\n",
    "    print(\"å°†ä½¿ç”¨çº¯PyTorchå®ç°æµ‹è¯•å‡½æ•°...\")\n",
    "\n",
    "if numpy_available:\n",
    "    # ä½¿ç”¨åŸå§‹çš„testå‡½æ•°\n",
    "    print(\"å¯¼å…¥testæ¨¡å—ï¼ˆå¯èƒ½éœ€è¦å‡ ç§’é’Ÿï¼‰...\")\n",
    "    from test import test\n",
    "    print(\"æµ‹è¯•æ¨¡å‹...\")\n",
    "    test_results = test(model, test_loader, args)\n",
    "else:\n",
    "    # ä½¿ç”¨çº¯PyTorchå®ç°çš„æµ‹è¯•å‡½æ•°\n",
    "    print(\"ä½¿ç”¨çº¯PyTorchæµ‹è¯•å‡½æ•°...\")\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        correct = []\n",
    "        cong_correct = []\n",
    "        incong_correct = []\n",
    "        loc1_ctx0 = [[] for _ in range(args.grid_size)]\n",
    "        loc1_ctx1 = [[] for _ in range(args.grid_size)]\n",
    "        \n",
    "        for batch in test_loader:\n",
    "            ctx, f1, f2, y, info = batch\n",
    "            ctx = ctx.to(args.device)\n",
    "            f1 = f1.to(args.device)\n",
    "            f2 = f2.to(args.device)\n",
    "            y = y.to(args.device)\n",
    "            locs1 = info['loc1']\n",
    "            congs = info['cong']\n",
    "            \n",
    "            # è¿è¡Œæ¨¡å‹\n",
    "            y_hat, out = model(ctx, f1, f2)\n",
    "            preds = torch.argmax(y_hat, dim=1)\n",
    "            \n",
    "            # è®¡ç®—æ­£ç¡®æ€§ï¼ˆä½¿ç”¨PyTorchï¼‰\n",
    "            c = (preds == y).cpu().tolist()  # è½¬æ¢ä¸ºPython listè€Œä¸æ˜¯numpy\n",
    "            correct += c\n",
    "            \n",
    "            # åˆ†ç±»ç»Ÿè®¡\n",
    "            for c_i, cong, ctx_i, loc1 in zip(c, congs, ctx.cpu().tolist(), locs1):\n",
    "                if cong == 1:\n",
    "                    cong_correct.append(c_i)\n",
    "                elif cong == -1:\n",
    "                    incong_correct.append(c_i)\n",
    "                \n",
    "                if ctx_i == 0:\n",
    "                    loc1_ctx0[loc1[0]].append(c_i)\n",
    "                elif ctx_i == 1:\n",
    "                    loc1_ctx1[loc1[1]].append(c_i)\n",
    "        \n",
    "        # è®¡ç®—å‡†ç¡®ç‡ï¼ˆä½¿ç”¨Pythonå†…ç½®å‡½æ•°ï¼‰\n",
    "        acc = sum(correct) / len(correct) if correct else 0.0\n",
    "        cong_acc = sum(cong_correct) / len(cong_correct) if cong_correct else 0.0\n",
    "        incong_acc = sum(incong_correct) / len(incong_correct) if incong_correct else 0.0\n",
    "        loc1_ctx0_acc = [sum(c0) / len(c0) if c0 else 0.0 for c0 in loc1_ctx0]\n",
    "        loc1_ctx1_acc = [sum(c1) / len(c1) if c1 else 0.0 for c1 in loc1_ctx1]\n",
    "        \n",
    "        test_results = {\n",
    "            'acc': acc,\n",
    "            'cong_acc': cong_acc,\n",
    "            'incong_acc': incong_acc,\n",
    "            'loc1_ctx0_acc': loc1_ctx0_acc,\n",
    "            'loc1_ctx1_acc': loc1_ctx1_acc\n",
    "        }\n",
    "    \n",
    "    model.train()\n",
    "\n",
    "print(f\"\\næµ‹è¯•ç»“æœ:\")\n",
    "print(f\"  æ€»ä½“å‡†ç¡®ç‡: {test_results['acc']:.4f}\")\n",
    "print(f\"  ä¸€è‡´å‡†ç¡®ç‡: {test_results['cong_acc']:.4f}\")\n",
    "print(f\"  ä¸ä¸€è‡´å‡†ç¡®ç‡: {test_results['incong_acc']:.4f}\")\n",
    "\n",
    "print(f\"\\nä¸Šä¸‹æ–‡0å„ç­‰çº§å‡†ç¡®ç‡ (Context 0 - ä¾‹å¦‚: Tasteç»´åº¦):\")\n",
    "print(f\"  è¯´æ˜: å½“ç¬¬ä¸€ä¸ªè‘¡è„é…’åœ¨ä¸Šä¸‹æ–‡0ä¸­çš„ç­‰çº§ä¸º0/1/2/3æ—¶ï¼Œæ¨¡å‹çš„å‡†ç¡®ç‡\")\n",
    "for i, acc in enumerate(test_results['loc1_ctx0_acc']):\n",
    "    print(f\"    ç­‰çº§ {i}: {acc:.4f}\")\n",
    "\n",
    "print(f\"\\nä¸Šä¸‹æ–‡1å„ç­‰çº§å‡†ç¡®ç‡ (Context 1 - ä¾‹å¦‚: Bodyç»´åº¦):\")\n",
    "print(f\"  è¯´æ˜: å½“ç¬¬ä¸€ä¸ªè‘¡è„é…’åœ¨ä¸Šä¸‹æ–‡1ä¸­çš„ç­‰çº§ä¸º0/1/2/3æ—¶ï¼Œæ¨¡å‹çš„å‡†ç¡®ç‡\")\n",
    "for i, acc in enumerate(test_results['loc1_ctx1_acc']):\n",
    "    print(f\"    ç­‰çº§ {i}: {acc:.4f}\")\n",
    "\n",
    "print(f\"\\nğŸ“ test.py åˆ†æå†…å®¹è¯¦è§£:\")\n",
    "print(f\"\\n1. æ€»ä½“å‡†ç¡®ç‡ (acc):\")\n",
    "print(f\"   - æ‰€æœ‰æµ‹è¯•æ ·æœ¬çš„å¹³å‡å‡†ç¡®ç‡\")\n",
    "print(f\"   - è¡¡é‡æ¨¡å‹çš„æ•´ä½“æ€§èƒ½\")\n",
    "print(f\"\\n2. ä¸€è‡´å‡†ç¡®ç‡ (cong_acc):\")\n",
    "print(f\"   - åªç»Ÿè®¡'ä¸€è‡´'æ ·æœ¬çš„å‡†ç¡®ç‡\")\n",
    "print(f\"   - 'ä¸€è‡´'æŒ‡ï¼šä¸¤ä¸ªç»´åº¦æ–¹å‘ç›¸åŒï¼ˆå¦‚éƒ½æ›´é«˜æˆ–éƒ½æ›´ä½ï¼‰\")\n",
    "print(f\"   - ä¾‹å¦‚ï¼šè‘¡è„é…’Aåœ¨Tasteå’ŒBodyä¸Šéƒ½æ¯”Bé«˜\")\n",
    "print(f\"\\n3. ä¸ä¸€è‡´å‡†ç¡®ç‡ (incong_acc):\")\n",
    "print(f\"   - åªç»Ÿè®¡'ä¸ä¸€è‡´'æ ·æœ¬çš„å‡†ç¡®ç‡\")\n",
    "print(f\"   - 'ä¸ä¸€è‡´'æŒ‡ï¼šä¸¤ä¸ªç»´åº¦æ–¹å‘ç›¸åï¼ˆä¸€ä¸ªæ›´é«˜ï¼Œå¦ä¸€ä¸ªæ›´ä½ï¼‰\")\n",
    "print(f\"   - ä¾‹å¦‚ï¼šè‘¡è„é…’Aåœ¨Tasteä¸Šæ¯”Bé«˜ï¼Œä½†åœ¨Bodyä¸Šæ¯”Bä½\")\n",
    "print(f\"   - ä¸ä¸€è‡´æ ·æœ¬æ›´éš¾ï¼Œå› ä¸ºéœ€è¦æ ¹æ®ä¸Šä¸‹æ–‡é€‰æ‹©æ­£ç¡®çš„ç»´åº¦\")\n",
    "print(f\"\\n4. ä¸Šä¸‹æ–‡0å„ç­‰çº§å‡†ç¡®ç‡ (loc1_ctx0_acc):\")\n",
    "print(f\"   - æŒ‰ç¬¬ä¸€ä¸ªè‘¡è„é…’åœ¨ä¸Šä¸‹æ–‡0ä¸­çš„ç­‰çº§ï¼ˆ0-3ï¼‰åˆ†ç±»ç»Ÿè®¡\")\n",
    "print(f\"   - æ£€æŸ¥æ¨¡å‹åœ¨ä¸åŒç­‰çº§ä¸Šçš„è¡¨ç°æ˜¯å¦ä¸€è‡´\")\n",
    "print(f\"\\n5. ä¸Šä¸‹æ–‡1å„ç­‰çº§å‡†ç¡®ç‡ (loc1_ctx1_acc):\")\n",
    "print(f\"   - æŒ‰ç¬¬ä¸€ä¸ªè‘¡è„é…’åœ¨ä¸Šä¸‹æ–‡1ä¸­çš„ç­‰çº§ï¼ˆ0-3ï¼‰åˆ†ç±»ç»Ÿè®¡\")\n",
    "print(f\"   - æ£€æŸ¥æ¨¡å‹åœ¨ä¸åŒç­‰çº§ä¸Šçš„è¡¨ç°æ˜¯å¦ä¸€è‡´\")\n",
    "print(f\"\\nğŸ’¡ åˆ†ææ„ä¹‰:\")\n",
    "print(f\"  - å¦‚æœcong_acc > incong_acc: è¯´æ˜æ¨¡å‹å¯¹ä¸€è‡´æ ·æœ¬å­¦ä¹ æ›´å¥½\")\n",
    "print(f\"  - å¦‚æœæŸäº›ç­‰çº§å‡†ç¡®ç‡ä½: è¯´æ˜æ¨¡å‹åœ¨è¯¥ç­‰çº§ä¸Šå­¦ä¹ ä¸è¶³\")\n",
    "print(f\"  - å¦‚æœä¸¤ä¸ªä¸Šä¸‹æ–‡è¡¨ç°å·®å¼‚å¤§: è¯´æ˜æ¨¡å‹å¯¹æŸä¸ªç»´åº¦å­¦ä¹ æ›´å¥½\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. å¯è§†åŒ–è®­ç»ƒè¿‡ç¨‹\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## âœ… æ¡†æ¶éªŒè¯å®Œæˆ\n",
    "\n",
    "æ­å–œï¼æ•´ä¸ªæ¡†æ¶å·²ç»åŸºæœ¬è·‘é€šäº†ã€‚ä»¥ä¸‹æ˜¯éªŒè¯çš„ç»„ä»¶ï¼š\n",
    "\n",
    "### å·²éªŒè¯çš„åŠŸèƒ½ï¼š\n",
    "\n",
    "1. âœ… **æ•°æ®ç”Ÿæˆ** (`GridDataGenerator`)\n",
    "   - æˆåŠŸç”Ÿæˆè®­ç»ƒ/æµ‹è¯•/åˆ†ææ•°æ®é›†\n",
    "   - æ”¯æŒä¸åŒçš„è®­ç»ƒæ¨¡å¼ï¼ˆungrouped, groupedç­‰ï¼‰\n",
    "\n",
    "2. âœ… **æ•°æ®åŠ è½½** (`GridDataset`, `DataLoader`)\n",
    "   - æ­£ç¡®åŠ è½½å’Œæ‰¹å¤„ç†æ•°æ®\n",
    "   - æ”¯æŒå›¾åƒå’Œç´¢å¼•ä¸¤ç§æ¨¡å¼\n",
    "\n",
    "3. âœ… **æ¨¡å‹åˆ›å»º** (`get_model`, `RNN`)\n",
    "   - æˆåŠŸåˆ›å»ºRNNæ¨¡å‹\n",
    "   - å‰å‘ä¼ æ’­æ­£å¸¸å·¥ä½œ\n",
    "\n",
    "4. âœ… **è®­ç»ƒæµç¨‹**\n",
    "   - è®­ç»ƒå¾ªç¯æ­£å¸¸è¿è¡Œ\n",
    "   - æŸå¤±ä¸‹é™æ­£å¸¸\n",
    "   - æ”¯æŒå¾ªç¯ä½¿ç”¨æ•°æ®ç›´åˆ°è¾¾åˆ°æŒ‡å®šæ­¥æ•°\n",
    "\n",
    "5. âœ… **æµ‹è¯•æµç¨‹** (`test`)\n",
    "   - æµ‹è¯•å‡½æ•°æ­£å¸¸å·¥ä½œ\n",
    "   - è®¡ç®—å¤šç§å‡†ç¡®ç‡æŒ‡æ ‡\n",
    "   - å¤„ç†äº†NumPyå…¼å®¹æ€§é—®é¢˜\n",
    "\n",
    "6. âœ… **ç»“æœåˆ†æ**\n",
    "   - å¾—åˆ°åˆç†çš„æµ‹è¯•ç»“æœ\n",
    "   - ä¸€è‡´/ä¸ä¸€è‡´å‡†ç¡®ç‡å·®å¼‚ç¬¦åˆé¢„æœŸ\n",
    "   - å¯è§†åŒ–åŠŸèƒ½æ­£å¸¸\n",
    "\n",
    "### æ¡†æ¶çŠ¶æ€ï¼šâœ… **å®Œå…¨å¯ç”¨**\n",
    "\n",
    "ä½ ç°åœ¨å¯ä»¥ï¼š\n",
    "- è°ƒæ•´è®­ç»ƒå‚æ•°è¿›è¡Œå®éªŒ\n",
    "- å°è¯•ä¸åŒçš„æ¨¡å‹ï¼ˆMLP, RNN, StepwiseMLPç­‰ï¼‰\n",
    "- ä½¿ç”¨Colabç‰ˆæœ¬åœ¨äº‘ç«¯è¿è¡Œ\n",
    "- è¿›è¡Œæ›´æ·±å…¥çš„åˆ†æ\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. æµ‹è¯• Countries Task\n",
    "\n",
    "æµ‹è¯•æ¨¡å‹åœ¨countries taskä¸Šçš„è¡¨ç°ã€‚Countries taskè¦æ±‚æ¨¡å‹æ ¹æ®ä¸åŒå›½å®¶çš„åå¥½é€‰æ‹©è‘¡è„é…’ã€‚\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'country_task'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# å¯¼å…¥countries taskæ¨¡å—\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mcountry_task\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m get_country_task_loaders, test_country_task\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# è·å–countries taskæ•°æ®åŠ è½½å™¨\u001b[39;00m\n\u001b[32m      5\u001b[39m \u001b[38;5;66;03m# éœ€è¦å…ˆæœ‰grid_data_genï¼Œæˆ‘ä»¬å¯ä»¥ä»ä¹‹å‰çš„æ•°æ®ç”Ÿæˆä¸­è·å–\u001b[39;00m\n\u001b[32m      6\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33måˆ›å»ºCountries Taskæ•°æ®...\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'country_task'"
     ]
    }
   ],
   "source": [
    "# å¯¼å…¥countries taskæ¨¡å—\n",
    "from country_task import get_country_task_loaders, test_country_task\n",
    "\n",
    "# è·å–countries taskæ•°æ®åŠ è½½å™¨\n",
    "# éœ€è¦å…ˆæœ‰grid_data_genï¼Œæˆ‘ä»¬å¯ä»¥ä»ä¹‹å‰çš„æ•°æ®ç”Ÿæˆä¸­è·å–\n",
    "print(\"åˆ›å»ºCountries Taskæ•°æ®...\")\n",
    "\n",
    "# é‡æ–°ç”Ÿæˆgridï¼ˆå¦‚æœéœ€è¦ï¼‰\n",
    "if 'grid' not in locals():\n",
    "    grid = GridDataGenerator(\n",
    "        training_regime=args.training_regime,\n",
    "        size=args.grid_size,\n",
    "        use_images=args.use_images,\n",
    "        image_dir=args.image_dir,\n",
    "        inner_4x4=args.inner_4x4\n",
    "    )\n",
    "\n",
    "# åˆ›å»ºcountries taskæ•°æ®åŠ è½½å™¨\n",
    "country_loader, country_data_gen = get_country_task_loaders(args, grid)\n",
    "\n",
    "print(f\"âœ“ Countries Taskæ•°æ®åˆ›å»ºå®Œæˆ\")\n",
    "print(f\"  å›½å®¶æ•°é‡: {country_data_gen.n_countries}\")\n",
    "print(f\"  æ€»æ ·æœ¬æ•°: {len(country_loader.dataset)}\")\n",
    "print(f\"\\nå›½å®¶åˆ—è¡¨:\")\n",
    "print(\"1Då›½å®¶ (4ä¸ªï¼Œæ–¹å‘äº’ä¸ç›¸åŒ):\")\n",
    "single_countries = []\n",
    "for i, country_info in enumerate(country_data_gen.countries):\n",
    "    name = country_info[0]\n",
    "    pref_type = country_info[1]\n",
    "    if pref_type == 'single':\n",
    "        attrs = country_info[2]\n",
    "        direction = country_info[3] if len(country_info) > 3 else 1\n",
    "        dir_desc = \"é«˜æ›´å¥½\" if direction == 1 else \"ä½æ›´å¥½\"\n",
    "        single_countries.append((i, name, attrs[0], direction, dir_desc))\n",
    "\n",
    "for i, name, ctx_idx, direction, dir_desc in single_countries:\n",
    "    print(f\"  {i}. {name}: å…³å¿ƒä¸Šä¸‹æ–‡{ctx_idx} ({dir_desc})\")\n",
    "\n",
    "print(\"\\n2Då›½å®¶ (4ä¸ªï¼Œæ–¹å‘ç»„åˆäº’ä¸ç›¸åŒ):\")\n",
    "dual_countries = []\n",
    "for i, country_info in enumerate(country_data_gen.countries):\n",
    "    name = country_info[0]\n",
    "    pref_type = country_info[1]\n",
    "    if pref_type == 'dual':\n",
    "        attrs = country_info[2]\n",
    "        direction = country_info[3] if len(country_info) > 3 else (1, 1)\n",
    "        dir1_desc = \"é«˜\" if direction[0] == 1 else \"ä½\"\n",
    "        dir2_desc = \"é«˜\" if direction[1] == 1 else \"ä½\"\n",
    "        dual_countries.append((i, name, attrs[0], attrs[1], direction, dir1_desc, dir2_desc))\n",
    "\n",
    "for i, name, ctx_idx1, ctx_idx2, direction, dir1_desc, dir2_desc in dual_countries:\n",
    "    print(f\"  {i}. {name}: å…³å¿ƒä¸Šä¸‹æ–‡{ctx_idx1}({dir1_desc})å’Œä¸Šä¸‹æ–‡{ctx_idx2}({dir2_desc})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "æµ‹è¯•æ¨¡å‹åœ¨Countries Taskä¸Šçš„è¡¨ç°...\n",
      "æ³¨æ„: æ¨¡å‹éœ€è¦æ ¹æ®æ¯ä¸ªå›½å®¶çš„åå¥½é€‰æ‹©æ­£ç¡®çš„è‘¡è„é…’\n",
      "\n",
      "\n",
      "ğŸ“Š Countries Task æµ‹è¯•ç»“æœ:\n",
      "\n",
      "1. æ€»ä½“å‡†ç¡®ç‡: 0.5781 (57.81%)\n",
      "\n",
      "2. æŒ‰åå¥½ç±»å‹åˆ†ç±»:\n",
      "   å•å±æ€§å›½å®¶å‡†ç¡®ç‡: 0.3250 (32.50%)\n",
      "   åŒå±æ€§å›½å®¶å‡†ç¡®ç‡: 1.0000 (100.00%)\n",
      "\n",
      "3. æŒ‰å›½å®¶åˆ†ç±»:\n",
      "   Country_A (1D-ä¸Šä¸‹æ–‡0(é«˜æ›´å¥½)): 0.2812 (28.12%)\n",
      "   Country_B (1D-ä¸Šä¸‹æ–‡1(é«˜æ›´å¥½)): 0.3750 (37.50%)\n",
      "   Country_C (1D-ä¸Šä¸‹æ–‡0(é«˜æ›´å¥½)): 0.3750 (37.50%)\n",
      "   Country_D (1D-ä¸Šä¸‹æ–‡1(é«˜æ›´å¥½)): 0.3125 (31.25%)\n",
      "   Country_E (2D-ä¸Šä¸‹æ–‡0(é«˜)+ä¸Šä¸‹æ–‡1(é«˜)): 1.0000 (100.00%)\n",
      "   Country_F (2D-ä¸Šä¸‹æ–‡0(é«˜)+ä¸Šä¸‹æ–‡1(é«˜)): 1.0000 (100.00%)\n",
      "   Country_G (1D-ä¸Šä¸‹æ–‡0(é«˜æ›´å¥½)): 0.2812 (28.12%)\n",
      "   Country_H (2D-ä¸Šä¸‹æ–‡0(é«˜)+ä¸Šä¸‹æ–‡1(é«˜)): 1.0000 (100.00%)\n",
      "\n",
      "4. ç‰¹æ®Šè¯•éªŒç±»å‹:\n",
      "   ç§©å·®ä¸º0 (ä¸Šä¸‹æ–‡0): 0.6863 (68.63%)\n",
      "   ç§©å·®ä¸º0 (ä¸Šä¸‹æ–‡1): 0.6538 (65.38%)\n",
      "   2Dè¯•éªŒ (ä¸¤ä¸ªç»´åº¦ç§©å·®éƒ½ä¸º0): 0.0000 (0.00%)\n",
      "   (éšæœºçŒœæµ‹: 33.33%, è¦æ±‚: >66%)\n",
      "   âš  2Dè¯•éªŒå‡†ç¡®ç‡æœªè¾¾åˆ°è¦æ±‚ï¼ˆéœ€è¦>66%ï¼‰\n"
     ]
    }
   ],
   "source": [
    "# æµ‹è¯•æ¨¡å‹åœ¨countries taskä¸Šçš„è¡¨ç°\n",
    "print(\"æµ‹è¯•æ¨¡å‹åœ¨Countries Taskä¸Šçš„è¡¨ç°...\")\n",
    "print(\"æ³¨æ„: æ¨¡å‹éœ€è¦æ ¹æ®æ¯ä¸ªå›½å®¶çš„åå¥½é€‰æ‹©æ­£ç¡®çš„è‘¡è„é…’\\n\")\n",
    "\n",
    "country_results = test_country_task(model, country_loader, args, country_data_gen)\n",
    "\n",
    "print(f\"\\nğŸ“Š Countries Task æµ‹è¯•ç»“æœ:\")\n",
    "print(f\"\\n1. æ€»ä½“å‡†ç¡®ç‡: {country_results['overall_acc']:.4f} ({country_results['overall_acc']*100:.2f}%)\")\n",
    "\n",
    "print(f\"\\n2. æŒ‰åå¥½ç±»å‹åˆ†ç±»:\")\n",
    "print(f\"   å•å±æ€§å›½å®¶å‡†ç¡®ç‡: {country_results['single_pref_acc']:.4f} ({country_results['single_pref_acc']*100:.2f}%)\")\n",
    "print(f\"   åŒå±æ€§å›½å®¶å‡†ç¡®ç‡: {country_results['dual_pref_acc']:.4f} ({country_results['dual_pref_acc']*100:.2f}%)\")\n",
    "\n",
    "print(f\"\\n3. æŒ‰å›½å®¶åˆ†ç±»:\")\n",
    "for i, country_name in enumerate(country_results['country_names']):\n",
    "    acc = country_results['country_acc'][i]\n",
    "    country_info = country_data_gen.countries[i]\n",
    "    pref_type = country_info[1]\n",
    "    attrs = country_info[2]\n",
    "    direction = country_info[3] if len(country_info) > 3 else (1 if pref_type == 'single' else (1, 1))\n",
    "    \n",
    "    if pref_type == 'single':\n",
    "        dir_desc = \"é«˜æ›´å¥½\" if direction == 1 else \"ä½æ›´å¥½\"\n",
    "        pref_desc = f\"1D-ä¸Šä¸‹æ–‡{attrs[0]}({dir_desc})\"\n",
    "    else:\n",
    "        dir1_desc = \"é«˜\" if direction[0] == 1 else \"ä½\"\n",
    "        dir2_desc = \"é«˜\" if direction[1] == 1 else \"ä½\"\n",
    "        pref_desc = f\"2D-ä¸Šä¸‹æ–‡{attrs[0]}({dir1_desc})+ä¸Šä¸‹æ–‡{attrs[1]}({dir2_desc})\"\n",
    "    print(f\"   {country_name} ({pref_desc}): {acc:.4f} ({acc*100:.2f}%)\")\n",
    "\n",
    "print(f\"\\n4. ç‰¹æ®Šè¯•éªŒç±»å‹:\")\n",
    "print(f\"   ç§©å·®ä¸º0 (ä¸Šä¸‹æ–‡0): {country_results['rank_diff_0_acc']:.4f} ({country_results['rank_diff_0_acc']*100:.2f}%)\")\n",
    "print(f\"   ç§©å·®ä¸º0 (ä¸Šä¸‹æ–‡1): {country_results['rank_diff_1_acc']:.4f} ({country_results['rank_diff_1_acc']*100:.2f}%)\")\n",
    "print(f\"   2Dè¯•éªŒ (ä¸¤ä¸ªç»´åº¦ç§©å·®éƒ½ä¸º0): {country_results['rank_diff_2d_acc']:.4f} ({country_results['rank_diff_2d_acc']*100:.2f}%)\")\n",
    "print(f\"   (éšæœºçŒœæµ‹: 33.33%, è¦æ±‚: >66%)\")\n",
    "\n",
    "if country_results['rank_diff_2d_acc'] > 0.66:\n",
    "    print(f\"   âœ“ 2Dè¯•éªŒå‡†ç¡®ç‡æ»¡è¶³è¦æ±‚ï¼ˆ>66%ï¼‰\")\n",
    "else:\n",
    "    print(f\"   âš  2Dè¯•éªŒå‡†ç¡®ç‡æœªè¾¾åˆ°è¦æ±‚ï¼ˆéœ€è¦>66%ï¼‰\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'matplotlib'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[17]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# å¯è§†åŒ–Countries Taskç»“æœ\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmatplotlib\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mplt\u001b[39;00m\n\u001b[32m      4\u001b[39m fig, axes = plt.subplots(\u001b[32m1\u001b[39m, \u001b[32m3\u001b[39m, figsize=(\u001b[32m18\u001b[39m, \u001b[32m5\u001b[39m))\n\u001b[32m      6\u001b[39m \u001b[38;5;66;03m# 1. æ€»ä½“å’Œåå¥½ç±»å‹å‡†ç¡®ç‡\u001b[39;00m\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'matplotlib'"
     ]
    }
   ],
   "source": [
    "# å¯è§†åŒ–Countries Taskç»“æœ\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "# 1. æ€»ä½“å’Œåå¥½ç±»å‹å‡†ç¡®ç‡\n",
    "ax1 = axes[0]\n",
    "categories = ['æ€»ä½“', 'å•å±æ€§å›½å®¶', 'åŒå±æ€§å›½å®¶']\n",
    "accs = [\n",
    "    country_results['overall_acc'],\n",
    "    country_results['single_pref_acc'],\n",
    "    country_results['dual_pref_acc']\n",
    "]\n",
    "colors = ['#2ecc71', '#3498db', '#e74c3c']\n",
    "bars = ax1.bar(categories, accs, color=colors, alpha=0.7, edgecolor='black', linewidth=1.5)\n",
    "for bar, acc in zip(bars, accs):\n",
    "    height = bar.get_height()\n",
    "    ax1.text(bar.get_x() + bar.get_width()/2., height,\n",
    "            f'{acc:.3f}\\n({acc*100:.1f}%)',\n",
    "            ha='center', va='bottom', fontweight='bold')\n",
    "ax1.set_ylabel('å‡†ç¡®ç‡', fontweight='bold')\n",
    "ax1.set_title('Countries Task - æ€»ä½“è¡¨ç°', fontweight='bold')\n",
    "ax1.set_ylim([0, 1.1])\n",
    "ax1.axhline(y=0.5, color='gray', linestyle='--', alpha=0.5, label='éšæœºçŒœæµ‹')\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# 2. å„å›½å®¶å‡†ç¡®ç‡\n",
    "ax2 = axes[1]\n",
    "country_names = country_results['country_names']\n",
    "country_accs = [country_results['country_acc'][i] for i in range(len(country_names))]\n",
    "colors_country = ['#3498db' if country_data_gen.countries[i][1] == 'single' else '#e74c3c' \n",
    "                  for i in range(len(country_names))]\n",
    "bars2 = ax2.bar(range(len(country_names)), country_accs, color=colors_country, alpha=0.7, \n",
    "                edgecolor='black', linewidth=1.5)\n",
    "for i, (bar, acc) in enumerate(zip(bars2, country_accs)):\n",
    "    height = bar.get_height()\n",
    "    ax2.text(bar.get_x() + bar.get_width()/2., height,\n",
    "            f'{acc:.2f}',\n",
    "            ha='center', va='bottom', fontsize=9, fontweight='bold')\n",
    "ax2.set_xticks(range(len(country_names)))\n",
    "ax2.set_xticklabels(country_names, rotation=45, ha='right')\n",
    "ax2.set_ylabel('å‡†ç¡®ç‡', fontweight='bold')\n",
    "ax2.set_title('Countries Task - å„å›½å®¶è¡¨ç°', fontweight='bold')\n",
    "ax2.set_ylim([0, 1.1])\n",
    "ax2.axhline(y=0.5, color='gray', linestyle='--', alpha=0.5)\n",
    "ax2.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# 3. ç‰¹æ®Šè¯•éªŒç±»å‹\n",
    "ax3 = axes[2]\n",
    "special_categories = ['ç§©å·®=0\\n(ä¸Šä¸‹æ–‡0)', 'ç§©å·®=0\\n(ä¸Šä¸‹æ–‡1)', '2Dè¯•éªŒ\\n(ä¸¤ä¸ªéƒ½=0)']\n",
    "special_accs = [\n",
    "    country_results['rank_diff_0_acc'],\n",
    "    country_results['rank_diff_1_acc'],\n",
    "    country_results['rank_diff_2d_acc']\n",
    "]\n",
    "bars3 = ax3.bar(special_categories, special_accs, color=['#f39c12', '#f39c12', '#9b59b6'], \n",
    "                alpha=0.7, edgecolor='black', linewidth=1.5)\n",
    "for bar, acc in zip(bars3, special_accs):\n",
    "    height = bar.get_height()\n",
    "    ax3.text(bar.get_x() + bar.get_width()/2., height,\n",
    "            f'{acc:.3f}\\n({acc*100:.1f}%)',\n",
    "            ha='center', va='bottom', fontweight='bold')\n",
    "ax3.set_ylabel('å‡†ç¡®ç‡', fontweight='bold')\n",
    "ax3.set_title('Countries Task - ç‰¹æ®Šè¯•éªŒç±»å‹', fontweight='bold')\n",
    "ax3.set_ylim([0, 1.1])\n",
    "ax3.axhline(y=0.33, color='gray', linestyle='--', alpha=0.5, label='éšæœºçŒœæµ‹ (33%)')\n",
    "ax3.axhline(y=0.66, color='green', linestyle='--', alpha=0.5, label='è¦æ±‚ (>66%)')\n",
    "ax3.legend()\n",
    "ax3.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"âœ“ å¯è§†åŒ–å®Œæˆ\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Meta-Learning è®­ç»ƒå’Œæµ‹è¯•\n",
    "\n",
    "ä½¿ç”¨Meta-Learningæ–¹æ³•è®­ç»ƒRNNï¼Œä½¿å…¶èƒ½å¤Ÿä»1Dè§„åˆ™å¿«é€Ÿå­¦ä¹ å¹¶æ³›åŒ–åˆ°2Dç»„åˆä»»åŠ¡ã€‚\n",
    "\n",
    "### Meta-Learningæ ¸å¿ƒæ€æƒ³ï¼š\n",
    "1. **Meta-Training (å¤–å¾ªç¯)**: è®­ç»ƒRNNæˆä¸ºä¸€ä¸ª\"å¿«é€Ÿå­¦ä¹ å™¨\"\n",
    "   - é€šè¿‡å¤§é‡éšæœºä»»åŠ¡ï¼Œè®©RNNå­¦ä¹ \"å¦‚ä½•å­¦ä¹ \"\n",
    "   - RNNé€šè¿‡éšè—çŠ¶æ€é€‚åº”æ–°ä»»åŠ¡ï¼Œè€Œä¸æ”¹å˜æƒé‡Î¸\n",
    "   \n",
    "2. **Meta-Testing (å†…å¾ªç¯)**: åœ¨çœŸå®ä»»åŠ¡ä¸Šæµ‹è¯•\n",
    "   - å†»ç»“æƒé‡Î¸_final\n",
    "   - é€šè¿‡1Dæ”¯æŒé›†é€‚åº”ï¼ˆæ¨¡æ‹Ÿäººç±»å­¦ä¹ ï¼‰\n",
    "   - åœ¨2DæŸ¥è¯¢é›†ä¸Šæµ‹è¯•ï¼ˆæ¨¡æ‹Ÿäººç±»æµ‹è¯•ï¼‰\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'meta_learning'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# å¯¼å…¥meta-learningæ¨¡å—\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmeta_learning\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m meta_train, meta_test, create_meta_learning_args, SequentialRNN\n\u001b[32m      4\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mâœ“ Meta-Learningæ¨¡å—å·²å¯¼å…¥\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      5\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mè¯´æ˜:\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'meta_learning'"
     ]
    }
   ],
   "source": [
    "# å¯¼å…¥meta-learningæ¨¡å—\n",
    "from meta_learning import meta_train, meta_test, create_meta_learning_args, SequentialRNN\n",
    "\n",
    "print(\"âœ“ Meta-Learningæ¨¡å—å·²å¯¼å…¥\")\n",
    "print(\"\\nè¯´æ˜:\")\n",
    "print(\"1. meta_train: è¿›è¡ŒMeta-Trainingï¼ˆå¤–å¾ªç¯ï¼‰\")\n",
    "print(\"2. meta_test: è¿›è¡ŒMeta-Testingï¼ˆå†…å¾ªç¯ï¼‰\")\n",
    "print(\"3. SequentialRNN: æ”¯æŒåºåˆ—è¾“å…¥çš„RNNåŒ…è£…å™¨\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.1 Meta-Training (å¤–å¾ªç¯)\n",
    "\n",
    "è®­ç»ƒRNNæˆä¸ºä¸€ä¸ª\"å¿«é€Ÿå­¦ä¹ å™¨\"ã€‚è¿™ä¸ªè¿‡ç¨‹ä¼šï¼š\n",
    "- ç”Ÿæˆå¤§é‡éšæœºä»»åŠ¡ï¼ˆæ¯ä¸ªä»»åŠ¡æ˜¯ä¸€ä¸ªæ–°çš„4x4åœ°å›¾ï¼‰\n",
    "- æ¯ä¸ªä»»åŠ¡åŒ…å«1Dæ”¯æŒé›†å’Œ2DæŸ¥è¯¢é›†\n",
    "- RNNé€šè¿‡éšè—çŠ¶æ€é€‚åº”æ¯ä¸ªä»»åŠ¡ï¼Œç„¶ååŸºäºæŸ¥è¯¢é›†çš„è¡¨ç°æ›´æ–°æƒé‡\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# åˆ›å»ºmeta-learningå‚æ•°\n",
    "meta_args = create_meta_learning_args(args)\n",
    "\n",
    "# è®¾ç½®meta-learningå‚æ•°\n",
    "meta_args.meta_lr = 0.001\n",
    "meta_args.n_support = 16  # æ¯ä¸ªä»»åŠ¡çš„1Dæ”¯æŒæ ·æœ¬æ•°\n",
    "meta_args.n_query = 32    # æ¯ä¸ªä»»åŠ¡çš„2DæŸ¥è¯¢æ ·æœ¬æ•°\n",
    "meta_args.n_meta_iterations = 1000  # Meta-trainingè¿­ä»£æ¬¡æ•°ï¼ˆæµ‹è¯•ç”¨ï¼Œå®é™…åº”è¯¥æ›´å¤šï¼‰\n",
    "meta_args.n_tasks_per_batch = 4   # æ¯æ‰¹ä»»åŠ¡æ•°\n",
    "\n",
    "print(\"Meta-Learningå‚æ•°è®¾ç½®:\")\n",
    "print(f\"  Metaå­¦ä¹ ç‡: {meta_args.meta_lr}\")\n",
    "print(f\"  Supporté›†å¤§å°: {meta_args.n_support}\")\n",
    "print(f\"  Queryé›†å¤§å°: {meta_args.n_query}\")\n",
    "print(f\"  Metaè¿­ä»£æ¬¡æ•°: {meta_args.n_meta_iterations}\")\n",
    "print(f\"  æ¯æ‰¹ä»»åŠ¡æ•°: {meta_args.n_tasks_per_batch}\")\n",
    "\n",
    "# åˆ›å»ºæ–°æ¨¡å‹ç”¨äºmeta-training\n",
    "meta_model = get_model(meta_args)\n",
    "meta_model.to(meta_args.device)\n",
    "\n",
    "print(f\"\\nå¼€å§‹Meta-Training...\")\n",
    "print(\"æ³¨æ„: è¿™ä¸ªè¿‡ç¨‹å¯èƒ½éœ€è¦è¾ƒé•¿æ—¶é—´ï¼Œå› ä¸ºéœ€è¦ç”Ÿæˆå¤§é‡éšæœºä»»åŠ¡\")\n",
    "print(\"     å®é™…ä½¿ç”¨æ—¶ï¼Œå»ºè®®è®¾ç½® n_meta_iterations >= 10000\\n\")\n",
    "\n",
    "# æ‰§è¡Œmeta-training\n",
    "# æ³¨æ„: è¿™é‡Œä½¿ç”¨è¾ƒå°çš„è¿­ä»£æ¬¡æ•°ç”¨äºæ¼”ç¤ºï¼Œå®é™…è®­ç»ƒåº”è¯¥ä½¿ç”¨æ›´å¤šè¿­ä»£\n",
    "meta_trained_model, meta_losses = meta_train(\n",
    "    meta_model, \n",
    "    meta_args,\n",
    "    n_meta_iterations=meta_args.n_meta_iterations,\n",
    "    n_tasks_per_batch=meta_args.n_tasks_per_batch\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.2 Meta-Testing (å†…å¾ªç¯)\n",
    "\n",
    "åœ¨çœŸå®çš„å›½å®¶ä»»åŠ¡ä¸Šæµ‹è¯•meta-trained RNNï¼š\n",
    "1. å†»ç»“æ¨¡å‹æƒé‡\n",
    "2. å¯¹æ¯ä¸ªå›½å®¶ï¼š\n",
    "   - ä½¿ç”¨1Dæ”¯æŒé›†è¿›è¡Œé€‚åº”ï¼ˆæ¨¡æ‹Ÿäººç±»å­¦ä¹ é˜¶æ®µï¼‰\n",
    "   - åœ¨2DæŸ¥è¯¢é›†ä¸Šæµ‹è¯•ï¼ˆæ¨¡æ‹Ÿäººç±»æµ‹è¯•é˜¶æ®µï¼‰\n",
    "3. æ¯”è¾ƒRNNè¡¨ç°ä¸äººç±»åŸºçº¿\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# å‡†å¤‡æµ‹è¯•æ•°æ®\n",
    "# ä½¿ç”¨ä¹‹å‰åˆ›å»ºçš„gridå’Œcountry_data_gen\n",
    "if 'grid' not in locals():\n",
    "    grid = GridDataGenerator(\n",
    "        training_regime=args.training_regime,\n",
    "        size=args.grid_size,\n",
    "        use_images=args.use_images,\n",
    "        image_dir=args.image_dir,\n",
    "        inner_4x4=args.inner_4x4\n",
    "    )\n",
    "\n",
    "if 'country_loader' not in locals() or 'country_data_gen' not in locals():\n",
    "    from country_task import get_country_task_loaders\n",
    "    country_loader, country_data_gen = get_country_task_loaders(args, grid)\n",
    "\n",
    "print(\"å¼€å§‹Meta-Testing...\")\n",
    "print(\"  æ¨¡å‹æƒé‡å·²å†»ç»“\")\n",
    "print(\"  æµ‹è¯•çœŸå®å›½å®¶ä»»åŠ¡\\n\")\n",
    "\n",
    "# æ‰§è¡Œmeta-testing\n",
    "meta_test_results = meta_test(\n",
    "    meta_trained_model,\n",
    "    meta_args,\n",
    "    grid,\n",
    "    country_data_gen,\n",
    "    country_loader\n",
    ")\n",
    "\n",
    "print(\"\\nğŸ“Š Meta-Testing ç»“æœæ€»ç»“:\")\n",
    "print(\"=\" * 50)\n",
    "for country_name, acc in meta_test_results.items():\n",
    "    print(f\"  {country_name}: {acc:.4f} ({acc*100:.2f}%)\")\n",
    "\n",
    "avg_acc = sum(meta_test_results.values()) / len(meta_test_results)\n",
    "print(f\"\\n  å¹³å‡å‡†ç¡®ç‡: {avg_acc:.4f} ({avg_acc*100:.2f}%)\")\n",
    "print(f\"  éšæœºçŒœæµ‹åŸºçº¿: 33.33% (3é€‰1)\")\n",
    "print(f\"  äººç±»åŸºçº¿: ~66-80% (æ ¹æ®è®ºæ–‡)\")\n",
    "\n",
    "if avg_acc > 0.66:\n",
    "    print(f\"\\n  âœ“ Meta-LearningæˆåŠŸï¼å‡†ç¡®ç‡è¶…è¿‡äººç±»åŸºçº¿ä¸‹é™\")\n",
    "elif avg_acc > 0.33:\n",
    "    print(f\"\\n  âš  Meta-Learningéƒ¨åˆ†æˆåŠŸï¼Œä½†æœªè¾¾åˆ°äººç±»åŸºçº¿\")\n",
    "else:\n",
    "    print(f\"\\n  âœ— Meta-Learningéœ€è¦è¿›ä¸€æ­¥ä¼˜åŒ–\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# å¯è§†åŒ–æŸå¤±æ›²çº¿\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(losses)\n",
    "plt.xlabel('Step')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training Loss')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# è®¡ç®—ç§»åŠ¨å¹³å‡\n",
    "window = 10\n",
    "if len(losses) >= window:\n",
    "    moving_avg = np.convolve(losses, np.ones(window)/window, mode='valid')\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(losses, alpha=0.3, label='Raw')\n",
    "    plt.plot(range(window-1, len(losses)), moving_avg, label=f'Moving Average (window={window})')\n",
    "    plt.xlabel('Step')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Training Loss (with moving average)')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. å®Œæ•´è®­ç»ƒæµç¨‹ï¼ˆä½¿ç”¨trainå‡½æ•°ï¼‰\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ä½¿ç”¨å®Œæ•´çš„trainå‡½æ•°è¿›è¡Œè®­ç»ƒ\n",
    "print(\"å¯¼å…¥trainæ¨¡å—ï¼ˆå¯èƒ½éœ€è¦å‡ ç§’é’Ÿï¼Œå› ä¸ºå®ƒä¼šå¯¼å…¥analyzeæ¨¡å—ï¼‰...\")\n",
    "from train import train\n",
    "\n",
    "print(\"ä½¿ç”¨å®Œæ•´è®­ç»ƒå‡½æ•°...\")\n",
    "\n",
    "# é‡æ–°åˆ›å»ºæ¨¡å‹å’Œæ•°æ®\n",
    "model = get_model(args)\n",
    "model.to(args.device)\n",
    "data = get_loaders(args)\n",
    "\n",
    "# è¿è¡Œä¸€ä¸ªå®Œæ•´çš„è®­ç»ƒå¾ªç¯\n",
    "results, analyses = train(0, model, data, args)\n",
    "\n",
    "print(f\"\\nè®­ç»ƒç»“æœ:\")\n",
    "print(f\"  è®­ç»ƒæŸå¤±: {len(results['train_losses'])} ä¸ªè®°å½•ç‚¹\")\n",
    "print(f\"  è®­ç»ƒå‡†ç¡®ç‡: {len(results['train_accs'])} ä¸ªè®°å½•ç‚¹\")\n",
    "print(f\"  æµ‹è¯•å‡†ç¡®ç‡: {len(results['test_accs'])} ä¸ªè®°å½•ç‚¹\")\n",
    "\n",
    "if results['train_accs']:\n",
    "    print(f\"\\næœ€ç»ˆå‡†ç¡®ç‡:\")\n",
    "    print(f\"  è®­ç»ƒ: {results['train_accs'][-1]['acc']:.4f}\")\n",
    "    print(f\"  æµ‹è¯•: {results['test_accs'][-1]['acc']:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## æ€»ç»“\n",
    "\n",
    "è¿™ä¸ªnotebookå±•ç¤ºäº†ï¼š\n",
    "1. âœ… æ•°æ®ç”Ÿæˆå’ŒåŠ è½½\n",
    "2. âœ… æ¨¡å‹åˆ›å»ºå’Œå‰å‘ä¼ æ’­\n",
    "3. âœ… è®­ç»ƒæµç¨‹\n",
    "4. âœ… æµ‹è¯•æµç¨‹\n",
    "5. âœ… å®Œæ•´è®­ç»ƒå‡½æ•°çš„ä½¿ç”¨\n",
    "\n",
    "æ‰€æœ‰ç»„ä»¶éƒ½æ­£å¸¸å·¥ä½œï¼\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
