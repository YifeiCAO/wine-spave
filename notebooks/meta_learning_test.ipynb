{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Meta-Learning V2 æµ‹è¯• Notebook\n",
    "\n",
    "æœ¬notebookç”¨äºæµ‹è¯•Meta-Learning V2æ–¹æ³•ï¼Œè®­ç»ƒRNNæˆä¸º\"å¿«é€Ÿå­¦ä¹ å™¨\"ï¼Œ\n",
    "ä½¿å…¶èƒ½å¤Ÿä»1Dè§„åˆ™å¿«é€Ÿé€‚åº”å¹¶æ³›åŒ–åˆ°2Dç»„åˆä»»åŠ¡ã€‚\n",
    "\n",
    "## æ ¸å¿ƒæ€æƒ³ï¼ˆV2ç‰ˆæœ¬ï¼‰\n",
    "- **Meta-Training**ï¼šè®­ç»ƒRNNå­¦ä¹ \"å¦‚ä½•å¿«é€Ÿå­¦ä¹ \"\n",
    "  - **Support Set**: 1Dè§„åˆ™æ ·æœ¬ï¼ˆSweet, Dry, Light, Fullï¼‰\n",
    "    - ä½¿ç”¨è§„åˆ™å‘é‡ `[1,0,0,0]`, `[0,1,0,0]`, `[0,0,1,0]`, `[0,0,0,1]`\n",
    "    - æ¯ä¸ªè§„åˆ™ç”Ÿæˆå¤šä¸ªwine pairæ ·æœ¬\n",
    "  - **Query Set**: 2Dè§„åˆ™æ ·æœ¬ï¼ˆç»„åˆè§„åˆ™ï¼‰\n",
    "    - ä½¿ç”¨è§„åˆ™å‘é‡ `[1,0,1,0]`, `[1,0,0,1]`, `[0,1,1,0]`, `[0,1,0,1]`\n",
    "    - æµ‹è¯•é›¶æ ·æœ¬æ³›åŒ–åˆ°2Dç»„åˆè§„åˆ™\n",
    "- **Meta-Testing**ï¼šæµ‹è¯•1Dâ†’2Dçš„æ³›åŒ–èƒ½åŠ›\n",
    "- **è¾“å‡ºæ ¼å¼**: 3ç±» [Wine1èƒœ, Wine2èƒœ, å¹³å±€]\n",
    "\n",
    "## ğŸš€ Colabä½¿ç”¨è¯´æ˜\n",
    "1. **å¯ç”¨GPU**: Runtime -> Change runtime type -> GPU\n",
    "2. **æŒ‰é¡ºåºè¿è¡Œ**: ä»Cell 3å¼€å§‹ï¼ŒæŒ‰é¡ºåºè¿è¡Œæ‰€æœ‰ä»£ç å—\n",
    "   - Cell 3: å…‹éš†é¡¹ç›®\n",
    "   - Cell 4: å®‰è£…NumPy\n",
    "   - Cell 5: å®‰è£…ä¾èµ–å¹¶å¯¼å…¥æ¨¡å—\n",
    "   - åç»­cells: è®­ç»ƒå’Œæµ‹è¯•"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. åœ¨Colabä¸­å…‹éš†é¡¹ç›®ï¼ˆä»…Colabéœ€è¦ï¼‰\n",
    "\n",
    "**å¦‚æœè¿™æ˜¯ç¬¬ä¸€æ¬¡åœ¨Colabä¸­è¿è¡Œï¼Œè¯·å…ˆå…‹éš†é¡¹ç›®ï¼š**\n",
    "- ä»GitHubå…‹éš†é¡¹ç›®ï¼šhttps://github.com/YifeiCAO/wine-spave\n",
    "- è¿è¡Œä¸‹é¢çš„cellè‡ªåŠ¨å…‹éš†å¹¶è®¾ç½®é¡¹ç›®è·¯å¾„\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. ç¯å¢ƒè®¾ç½®å’Œä¾èµ–å®‰è£…\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "æœ¬åœ°ç¯å¢ƒï¼Œé¡¹ç›®æ ¹ç›®å½•: /Users/yifei/Desktop/UCLA/wine-spave\n"
     ]
    }
   ],
   "source": [
    "# åœ¨Colabä¸­å…‹éš†é¡¹ç›®ï¼ˆä»…Colabéœ€è¦ï¼‰\n",
    "import os\n",
    "import sys\n",
    "\n",
    "IN_COLAB = 'google.colab' in sys.modules\n",
    "\n",
    "if IN_COLAB:\n",
    "    # ä»GitHubå…‹éš†é¡¹ç›®\n",
    "    project_root = '/content/wine-spave'\n",
    "    \n",
    "    if not os.path.exists(project_root):\n",
    "        print(\"ğŸ“¦ ä»GitHubå…‹éš†é¡¹ç›®...\")\n",
    "        get_ipython().system('git clone https://github.com/YifeiCAO/wine-spave.git')\n",
    "        print(\"âœ“ é¡¹ç›®å…‹éš†å®Œæˆ\")\n",
    "    else:\n",
    "        print(\"âœ“ é¡¹ç›®å·²å­˜åœ¨ï¼Œè·³è¿‡å…‹éš†\")\n",
    "    \n",
    "    # åˆ‡æ¢åˆ°é¡¹ç›®ç›®å½•\n",
    "    os.chdir(project_root)\n",
    "    print(f\"âœ“ é¡¹ç›®æ ¹ç›®å½•: {project_root}\")\n",
    "    print(f\"âœ“ å½“å‰å·¥ä½œç›®å½•: {os.getcwd()}\")\n",
    "else:\n",
    "    # æœ¬åœ°ç¯å¢ƒ\n",
    "    current_dir = os.getcwd()\n",
    "    if 'notebooks' in current_dir:\n",
    "        project_root = os.path.dirname(current_dir)\n",
    "    else:\n",
    "        project_root = current_dir\n",
    "    print(f\"æœ¬åœ°ç¯å¢ƒï¼Œé¡¹ç›®æ ¹ç›®å½•: {project_root}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ä¿®å¤NumPyç‰ˆæœ¬å…¼å®¹æ€§ï¼ˆå¿…é¡»åœ¨å¯¼å…¥torchvisionä¹‹å‰ï¼‰\n",
    "import sys\n",
    "import subprocess\n",
    "\n",
    "IN_COLAB = 'google.colab' in sys.modules\n",
    "\n",
    "if IN_COLAB:\n",
    "    print(\"ğŸ”§ å®‰è£…NumPy 1.26.4ï¼ˆå…¼å®¹PyTorchï¼‰...\")\n",
    "    # æ¸…é™¤numpyæ¨¡å—ç¼“å­˜ï¼ˆå¦‚æœå·²å¯¼å…¥ï¼‰\n",
    "    if 'numpy' in sys.modules:\n",
    "        del sys.modules['numpy']\n",
    "    \n",
    "    # ç›´æ¥é‡æ–°å®‰è£…NumPy 1.26.4\n",
    "    try:\n",
    "        get_ipython().system('pip install -q --force-reinstall numpy==1.26.4')\n",
    "    except:\n",
    "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", \"--force-reinstall\", \"numpy==1.26.4\"])\n",
    "    \n",
    "    import numpy as np\n",
    "    print(f\"âœ“ NumPyå·²å®‰è£…: {np.__version__}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "é¡¹ç›®æ ¹ç›®å½•: /Users/yifei/Desktop/UCLA/wine-spave\n",
      "å½“å‰å·¥ä½œç›®å½•: /Users/yifei/Desktop/UCLA/wine-spave/notebooks\n",
      "âš  GPUä¸å¯ç”¨ï¼Œå°†ä½¿ç”¨CPU\n",
      "\n",
      "å¯¼å…¥é¡¹ç›®æ¨¡å—...\n",
      "âœ“ æ‰€æœ‰æ¨¡å—å¯¼å…¥å®Œæˆï¼ˆä½¿ç”¨Meta-Learning V2ï¼‰\n"
     ]
    }
   ],
   "source": [
    "# å®‰è£…å…¶ä»–ä¾èµ–å¹¶å¯¼å…¥æ¨¡å—\n",
    "import os\n",
    "import sys\n",
    "import random\n",
    "\n",
    "IN_COLAB = 'google.colab' in sys.modules\n",
    "\n",
    "# å®‰è£…ä¾èµ–\n",
    "if IN_COLAB:\n",
    "    print(\"ğŸ“¦ å®‰è£…ä¾èµ–åŒ…...\")\n",
    "    try:\n",
    "        get_ipython().system('pip install -q torch torchvision matplotlib tqdm')\n",
    "    except:\n",
    "        import subprocess\n",
    "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", \"torch\", \"torchvision\", \"matplotlib\", \"tqdm\"])\n",
    "    print(\"âœ“ ä¾èµ–åŒ…å®‰è£…å®Œæˆ\\n\")\n",
    "else:\n",
    "    # æœ¬åœ°ç¯å¢ƒï¼šæ£€æŸ¥ä¾èµ–\n",
    "    try:\n",
    "        import torch\n",
    "    except ImportError:\n",
    "        import subprocess\n",
    "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", \"torch\", \"torchvision\"])\n",
    "    \n",
    "    try:\n",
    "        import matplotlib\n",
    "    except ImportError:\n",
    "        import subprocess\n",
    "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", \"matplotlib\"])\n",
    "    \n",
    "    try:\n",
    "        import tqdm\n",
    "    except ImportError:\n",
    "        import subprocess\n",
    "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", \"tqdm\"])\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# è®¾ç½®é¡¹ç›®è·¯å¾„ï¼ˆåœ¨Colabä¸­ï¼ŒCell 3å·²ç»åˆ‡æ¢äº†å·¥ä½œç›®å½•ï¼‰\n",
    "if IN_COLAB:\n",
    "    # åœ¨Colabä¸­ï¼Œé¡¹ç›®åº”è¯¥åœ¨/content/wine-spaveï¼ˆCell 3å·²ç»åˆ‡æ¢åˆ°è¿™é‡Œï¼‰\n",
    "    project_root = '/content/wine-spave'\n",
    "    # ç¡®ä¿åœ¨é¡¹ç›®ç›®å½•ä¸­\n",
    "    if os.path.exists(project_root):\n",
    "        os.chdir(project_root)\n",
    "    else:\n",
    "        print(\"âš  è­¦å‘Š: æœªæ‰¾åˆ°wine-spaveç›®å½•ï¼Œè¯·å…ˆè¿è¡ŒCell 3å…‹éš†é¡¹ç›®\")\n",
    "        project_root = '/content'\n",
    "else:\n",
    "    # æœ¬åœ°ç¯å¢ƒ\n",
    "    current_dir = os.getcwd()\n",
    "    if 'notebooks' in current_dir:\n",
    "        project_root = os.path.dirname(current_dir)\n",
    "    else:\n",
    "        project_root = current_dir\n",
    "\n",
    "# æ·»åŠ é¡¹ç›®è·¯å¾„åˆ°sys.path\n",
    "if project_root not in sys.path:\n",
    "    sys.path.insert(0, project_root)\n",
    "\n",
    "print(f\"é¡¹ç›®æ ¹ç›®å½•: {project_root}\")\n",
    "print(f\"å½“å‰å·¥ä½œç›®å½•: {os.getcwd()}\")\n",
    "\n",
    "# GPUæ£€æµ‹\n",
    "if torch.cuda.is_available():\n",
    "    device = \"cuda\"\n",
    "    print(f\"âœ“ GPUå¯ç”¨: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"  GPUæ•°é‡: {torch.cuda.device_count()}\")\n",
    "    print(f\"  æ˜¾å­˜: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.2f} GB\")\n",
    "else:\n",
    "    device = \"cpu\"\n",
    "    print(\"âš  GPUä¸å¯ç”¨ï¼Œå°†ä½¿ç”¨CPU\")\n",
    "    if IN_COLAB:\n",
    "        print(\"  æç¤º: åœ¨Colabä¸­ï¼Œè¯·ç¡®ä¿å·²å¯ç”¨GPU: Runtime -> Change runtime type -> GPU\")\n",
    "\n",
    "# å¯¼å…¥é¡¹ç›®æ¨¡å—\n",
    "print(\"\\nå¯¼å…¥é¡¹ç›®æ¨¡å—...\")\n",
    "try:\n",
    "    from data import GridDataGenerator\n",
    "    from models import get_model\n",
    "    from meta_learning_v2 import (\n",
    "        meta_train_v2, \n",
    "        meta_test_v2\n",
    "    )\n",
    "    print(\"âœ“ æ‰€æœ‰æ¨¡å—å¯¼å…¥å®Œæˆï¼ˆä½¿ç”¨Meta-Learning V2ï¼‰\")\n",
    "except ImportError as e:\n",
    "    print(f\"âŒ å¯¼å…¥å¤±è´¥: {e}\")\n",
    "    print(f\"   è¯·ç¡®ä¿é¡¹ç›®æ–‡ä»¶å·²æ­£ç¡®ä¸Šä¼ åˆ°: {project_root}\")\n",
    "    print(f\"   å½“å‰sys.path: {sys.path[:3]}\")\n",
    "    raise\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "å‚æ•°è®¾ç½®å®Œæˆï¼ˆV2ç‰ˆæœ¬ï¼‰ï¼\n",
      "è®¾å¤‡: cpu\n",
      "æ¨¡å‹: rnn\n",
      "Metaå­¦ä¹ ç‡: 0.001\n",
      "Metaè¿­ä»£æ¬¡æ•°: 500\n",
      "æ¯ä¸ª1Dè§„åˆ™çš„Supportæ ·æœ¬æ•°: 16\n",
      "Query Setå¤§å°: 32\n",
      "è¾“å‡ºç±»åˆ«æ•°: 3 (Wine1èƒœ, Wine2èƒœ, å¹³å±€)\n"
     ]
    }
   ],
   "source": [
    "# åŸºç¡€å‚æ•°ç±»ï¼ˆV2ç‰ˆæœ¬ï¼‰\n",
    "class Args:\n",
    "    def __init__(self):\n",
    "        # è®¾å¤‡è®¾ç½®\n",
    "        self.use_cuda = torch.cuda.is_available()\n",
    "        self.device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "        self.seed = 42\n",
    "        \n",
    "        # æ•°æ®é›†è®¾ç½®\n",
    "        self.use_images = False\n",
    "        self.image_dir = 'images/faces16'\n",
    "        self.training_regime = 'ungrouped'\n",
    "        self.grid_size = 4\n",
    "        self.ctx_order = 'first'\n",
    "        self.inner_4x4 = False\n",
    "        \n",
    "        # æ¨¡å‹è®¾ç½®\n",
    "        self.model_name = 'rnn'\n",
    "        self.ctx_scale = 1.0\n",
    "        self.measure_grad_norm = False\n",
    "        \n",
    "        # Meta-Learning V2å‚æ•°\n",
    "        self.meta_lr = 0.001\n",
    "        # Support Set: æ¯ä¸ª1Dè§„åˆ™ï¼ˆSweet, Dry, Light, Fullï¼‰çš„æ ·æœ¬æ•°\n",
    "        self.n_support_per_rule = 16  # æ¯ä¸ª1Dè§„åˆ™ç”Ÿæˆ16ä¸ªæ ·æœ¬\n",
    "        # Query Set: 2Dè§„åˆ™æ ·æœ¬æ€»æ•°\n",
    "        self.n_query = 32  # ä»æ‰€æœ‰2Dè§„åˆ™æ ·æœ¬ä¸­éšæœºé‡‡æ ·32ä¸ª\n",
    "        self.n_meta_iterations = 500  # å¯ä»¥è°ƒæ•´ä¸ºâ‰¥10000ç”¨äºæ­£å¼è®­ç»ƒ\n",
    "        self.n_tasks_per_batch = 4\n",
    "\n",
    "# åˆ›å»ºå‚æ•°å¯¹è±¡\n",
    "args = Args()\n",
    "\n",
    "# è®¾ç½®éšæœºç§å­\n",
    "torch.manual_seed(args.seed)\n",
    "random.seed(args.seed)\n",
    "np.random.seed(args.seed)\n",
    "\n",
    "print(\"å‚æ•°è®¾ç½®å®Œæˆï¼ˆV2ç‰ˆæœ¬ï¼‰ï¼\")\n",
    "print(f\"è®¾å¤‡: {args.device}\")\n",
    "print(f\"æ¨¡å‹: {args.model_name}\")\n",
    "print(f\"Metaå­¦ä¹ ç‡: {args.meta_lr}\")\n",
    "print(f\"Metaè¿­ä»£æ¬¡æ•°: {args.n_meta_iterations}\")\n",
    "print(f\"æ¯ä¸ª1Dè§„åˆ™çš„Supportæ ·æœ¬æ•°: {args.n_support_per_rule}\")\n",
    "print(f\"Query Setå¤§å°: {args.n_query}\")\n",
    "print(f\"è¾“å‡ºç±»åˆ«æ•°: 3 (Wine1èƒœ, Wine2èƒœ, å¹³å±€)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model is an LSTM\n",
      "âœ“ æ¨¡å‹åˆ›å»ºå®Œæˆï¼ˆV2ç‰ˆæœ¬ï¼‰\n",
      "  æ¨¡å‹ç±»å‹: RNN\n",
      "  è®¾å¤‡: cpu\n",
      "  æ³¨æ„: æ¨¡å‹è¾“å‡ºç»´åº¦å°†åœ¨meta_train_v2ä¸­è‡ªåŠ¨è°ƒæ•´ä¸º3ç±»\n"
     ]
    }
   ],
   "source": [
    "# åˆ›å»ºæ¨¡å‹ï¼ˆV2ç‰ˆæœ¬ä¸éœ€è¦create_meta_learning_argsï¼‰\n",
    "model = get_model(args)\n",
    "model = model.to(args.device)\n",
    "\n",
    "print(f\"âœ“ æ¨¡å‹åˆ›å»ºå®Œæˆï¼ˆV2ç‰ˆæœ¬ï¼‰\")\n",
    "print(f\"  æ¨¡å‹ç±»å‹: {type(model).__name__}\")\n",
    "print(f\"  è®¾å¤‡: {args.device}\")\n",
    "print(f\"  æ³¨æ„: æ¨¡å‹è¾“å‡ºç»´åº¦å°†åœ¨meta_train_v2ä¸­è‡ªåŠ¨è°ƒæ•´ä¸º3ç±»\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ä¿®æ”¹æ¨¡å‹è¾“å‡ºç»´åº¦ä¸º3ç±»\n",
      "å¼€å§‹Meta-Training V2...\n",
      "  æ€»è¿­ä»£æ¬¡æ•°: 500\n",
      "  æ¯æ‰¹ä»»åŠ¡æ•°: 4\n",
      "  æ¯ä¸ª1Dè§„åˆ™çš„Supportæ ·æœ¬æ•°: 16\n",
      "  Query Setå¤§å°: 32\n",
      "  è¾“å‡ºç±»åˆ«æ•°: 3 (Wine1èƒœ, Wine2èƒœ, å¹³å±€)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Meta-Training V2:  19%|â–‰    | 97/500 [02:27<10:14,  1.53s/iter, Loss=1.0019, Avg=1.0427, Min=0.9913]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# æ‰§è¡Œmeta-training V2\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m meta_trained_model, meta_losses = \u001b[43mmeta_train_v2\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m    \u001b[49m\u001b[43mn_meta_iterations\u001b[49m\u001b[43m=\u001b[49m\u001b[43margs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mn_meta_iterations\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m    \u001b[49m\u001b[43mn_tasks_per_batch\u001b[49m\u001b[43m=\u001b[49m\u001b[43margs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mn_tasks_per_batch\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/UCLA/wine-spave/meta_learning_v2.py:401\u001b[39m, in \u001b[36mmeta_train_v2\u001b[39m\u001b[34m(model, args, n_meta_iterations, n_tasks_per_batch)\u001b[39m\n\u001b[32m    398\u001b[39m seq_model.base_rnn.grid = task.grid\n\u001b[32m    400\u001b[39m \u001b[38;5;66;03m# In-context learning: å¤„ç†æ”¯æŒé›†\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m401\u001b[39m support_outputs, adapted_hidden = \u001b[43mseq_model\u001b[49m\u001b[43m.\u001b[49m\u001b[43mforward_sequence\u001b[49m\u001b[43m(\u001b[49m\u001b[43msupport_samples\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    403\u001b[39m \u001b[38;5;66;03m# In-context testing: å¤„ç†æŸ¥è¯¢é›†ï¼ˆä½¿ç”¨é€‚åº”åçš„hidden stateï¼‰\u001b[39;00m\n\u001b[32m    404\u001b[39m query_outputs, _ = seq_model.forward_sequence(query_samples, adapted_hidden)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/UCLA/wine-spave/meta_learning_v2.py:318\u001b[39m, in \u001b[36mSequentialRNNV2.forward_sequence\u001b[39m\u001b[34m(self, samples, hidden_state)\u001b[39m\n\u001b[32m    315\u001b[39m     x = torch.cat([f1_embed, f2_embed, rule_embed], dim=\u001b[32m0\u001b[39m)  \u001b[38;5;66;03m# [3, batch, state_dim]\u001b[39;00m\n\u001b[32m    317\u001b[39m \u001b[38;5;66;03m# é€šè¿‡LSTMå¤„ç†ï¼ˆä¿æŒhidden stateï¼‰\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m318\u001b[39m lstm_out, (h_n, c_n) = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbase_rnn\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlstm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mh_n\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mc_n\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    320\u001b[39m \u001b[38;5;66;03m# ä»æœ€ç»ˆhidden stateè·å–è¾“å‡º\u001b[39;00m\n\u001b[32m    321\u001b[39m output = \u001b[38;5;28mself\u001b[39m.base_rnn.out(h_n.squeeze(\u001b[32m0\u001b[39m))  \u001b[38;5;66;03m# [batch, output_dim]\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/UCLA/wine-spave/.conda/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1509\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1510\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1511\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/UCLA/wine-spave/.conda/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1515\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1516\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1517\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1518\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1519\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1520\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1522\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1523\u001b[39m     result = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/UCLA/wine-spave/.conda/lib/python3.11/site-packages/torch/nn/modules/rnn.py:878\u001b[39m, in \u001b[36mLSTM.forward\u001b[39m\u001b[34m(self, input, hx)\u001b[39m\n\u001b[32m    875\u001b[39m         hx = \u001b[38;5;28mself\u001b[39m.permute_hidden(hx, sorted_indices)\n\u001b[32m    877\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m batch_sizes \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m878\u001b[39m     result = \u001b[43m_VF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlstm\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_flat_weights\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mnum_layers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    879\u001b[39m \u001b[43m                      \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdropout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbidirectional\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbatch_first\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    880\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    881\u001b[39m     result = _VF.lstm(\u001b[38;5;28minput\u001b[39m, batch_sizes, hx, \u001b[38;5;28mself\u001b[39m._flat_weights, \u001b[38;5;28mself\u001b[39m.bias,\n\u001b[32m    882\u001b[39m                       \u001b[38;5;28mself\u001b[39m.num_layers, \u001b[38;5;28mself\u001b[39m.dropout, \u001b[38;5;28mself\u001b[39m.training, \u001b[38;5;28mself\u001b[39m.bidirectional)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# æ‰§è¡Œmeta-training V2\n",
    "meta_trained_model, meta_losses = meta_train_v2(\n",
    "    model,\n",
    "    args,\n",
    "    n_meta_iterations=args.n_meta_iterations,\n",
    "    n_tasks_per_batch=args.n_tasks_per_batch\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# å¯è§†åŒ–è®­ç»ƒæŸå¤±\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "# åŸå§‹æŸå¤±\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(meta_losses, alpha=0.6, linewidth=1)\n",
    "plt.xlabel('Meta-Iteration')\n",
    "plt.ylabel('Meta-Loss')\n",
    "plt.title('Meta-Training Loss (Raw)')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# å¹³æ»‘æŸå¤±\n",
    "plt.subplot(1, 2, 2)\n",
    "window = min(100, len(meta_losses) // 10)\n",
    "if window > 1:\n",
    "    moving_avg = np.convolve(meta_losses, np.ones(window)/window, mode='valid')\n",
    "    plt.plot(meta_losses, alpha=0.3, label='Raw', linewidth=1)\n",
    "    plt.plot(range(window-1, len(meta_losses)), moving_avg, \n",
    "             label=f'Moving Average (window={window})', linewidth=2)\n",
    "else:\n",
    "    plt.plot(meta_losses, alpha=0.6, linewidth=1)\n",
    "plt.xlabel('Meta-Iteration')\n",
    "plt.ylabel('Meta-Loss')\n",
    "plt.title('Meta-Training Loss (Smoothed)')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"åˆå§‹Meta-Loss: {meta_losses[0]:.4f}\")\n",
    "print(f\"æœ€ç»ˆMeta-Loss: {meta_losses[-1]:.4f}\")\n",
    "if len(meta_losses) > 100:\n",
    "    print(f\"æœ€å100æ¬¡å¹³å‡: {np.mean(meta_losses[-100:]):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# æ‰§è¡Œmeta-testing V2ï¼ˆç›´æ¥æµ‹è¯•1Dâ†’2Dæ³›åŒ–ï¼‰\n",
    "# V2ç‰ˆæœ¬ä¸éœ€è¦é¢„å…ˆç”Ÿæˆgridï¼Œä¼šåœ¨å†…éƒ¨è‡ªåŠ¨ç”Ÿæˆ\n",
    "final_acc, accuracies = meta_test_v2(\n",
    "    meta_trained_model,\n",
    "    args,\n",
    "    n_test_tasks=20  # æµ‹è¯•20ä¸ªä»»åŠ¡\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ç»“æœæ€»ç»“ï¼ˆV2ç‰ˆæœ¬ï¼š3ç±»è¾“å‡ºï¼‰\n",
    "print(\"=\"*60)\n",
    "print(\"ğŸ“Š Meta-Testing V2 ç»“æœæ€»ç»“\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\næœ€ç»ˆå¹³å‡å‡†ç¡®ç‡: {final_acc:.4f} ({final_acc*100:.2f}%)\")\n",
    "print(f\"æµ‹è¯•ä»»åŠ¡æ•°: {len(accuracies)}\")\n",
    "print(f\"å‡†ç¡®ç‡èŒƒå›´: {min(accuracies):.4f} - {max(accuracies):.4f}\")\n",
    "print(f\"\\nåŸºçº¿æ¯”è¾ƒï¼ˆ3ç±»è¾“å‡ºï¼‰:\")\n",
    "print(f\"  éšæœºçŒœæµ‹: 33.33% (3é€‰1)\")\n",
    "print(f\"  äººç±»åŸºçº¿: ~66-80%\")\n",
    "\n",
    "# å¯è§†åŒ–\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "# å‡†ç¡®ç‡åˆ†å¸ƒ\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.hist(accuracies, bins=10, alpha=0.7, edgecolor='black')\n",
    "plt.axvline(final_acc, color='r', linestyle='--', linewidth=2, label=f'å¹³å‡: {final_acc:.3f}')\n",
    "plt.axvline(0.3333, color='gray', linestyle='--', alpha=0.5, label='éšæœºçŒœæµ‹ (33.33%)')\n",
    "plt.axvline(0.66, color='green', linestyle='--', alpha=0.5, label='äººç±»åŸºçº¿ (66%)')\n",
    "plt.xlabel('å‡†ç¡®ç‡')\n",
    "plt.ylabel('ä»»åŠ¡æ•°é‡')\n",
    "plt.title('Meta-Testing V2 å‡†ç¡®ç‡åˆ†å¸ƒ')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# å‡†ç¡®ç‡è¶‹åŠ¿\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(range(1, len(accuracies)+1), accuracies, 'o-', alpha=0.6, markersize=4)\n",
    "plt.axhline(final_acc, color='r', linestyle='--', linewidth=2, label=f'å¹³å‡: {final_acc:.3f}')\n",
    "plt.axhline(0.3333, color='gray', linestyle='--', alpha=0.5, label='éšæœºçŒœæµ‹ (33.33%)')\n",
    "plt.axhline(0.66, color='green', linestyle='--', alpha=0.5, label='äººç±»åŸºçº¿ (66%)')\n",
    "plt.xlabel('ä»»åŠ¡åºå·')\n",
    "plt.ylabel('å‡†ç¡®ç‡')\n",
    "plt.title('Meta-Testing V2 å‡†ç¡®ç‡è¶‹åŠ¿')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# è¯„ä¼°ç»“æœ\n",
    "print(f\"\\nè¯„ä¼°:\")\n",
    "if final_acc > 0.66:\n",
    "    print(f\"  âœ“ Meta-Learning V2æˆåŠŸï¼å‡†ç¡®ç‡({final_acc*100:.2f}%)è¶…è¿‡äººç±»åŸºçº¿ä¸‹é™\")\n",
    "elif final_acc > 0.3333:\n",
    "    print(f\"  âš  Meta-Learning V2éƒ¨åˆ†æˆåŠŸï¼Œå‡†ç¡®ç‡({final_acc*100:.2f}%)è¶…è¿‡éšæœºä½†æœªè¾¾åˆ°äººç±»åŸºçº¿\")\n",
    "else:\n",
    "    print(f\"  âœ— Meta-Learning V2éœ€è¦è¿›ä¸€æ­¥ä¼˜åŒ–ï¼Œå‡†ç¡®ç‡({final_acc*100:.2f}%)æ¥è¿‘éšæœºæ°´å¹³\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
