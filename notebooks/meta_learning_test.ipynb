{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Meta-Learning æµ‹è¯• Notebook (Colabç‰ˆæœ¬)\n",
        "\n",
        "æœ¬notebookä¸“é—¨ç”¨äºæµ‹è¯•Meta-Learningæ–¹æ³•ï¼Œè®­ç»ƒRNNæˆä¸º\"å¿«é€Ÿå­¦ä¹ å™¨\"ï¼Œ\n",
        "ä½¿å…¶èƒ½å¤Ÿä»1Dè§„åˆ™å¿«é€Ÿé€‚åº”å¹¶æ³›åŒ–åˆ°2Dç»„åˆä»»åŠ¡ã€‚\n",
        "\n",
        "## ğŸš€ Colabä½¿ç”¨è¯´æ˜\n",
        "\n",
        "1. **å¯ç”¨GPU**: Runtime -> Change runtime type -> GPU (T4/V100/A100)\n",
        "2. **ä¸Šä¼ é¡¹ç›®**: å°†é¡¹ç›®æ–‡ä»¶ä¸Šä¼ åˆ°Colabï¼Œæˆ–ä½¿ç”¨GitHubå…‹éš†\n",
        "3. **é‡è¦**: å¦‚æœé‡åˆ°NumPyç‰ˆæœ¬é”™è¯¯ï¼Œè¯·å…ˆè¿è¡ŒCell 3ä¿®å¤NumPyå…¼å®¹æ€§\n",
        "4. **è¿è¡Œæ‰€æœ‰Cells**: æŒ‰é¡ºåºè¿è¡Œæ‰€æœ‰ä»£ç å—\n",
        "\n",
        "## âš ï¸ å¸¸è§é—®é¢˜\n",
        "\n",
        "**å¦‚æœé‡åˆ° `ValueError: numpy.dtype size changed` é”™è¯¯**ï¼š\n",
        "1. å…ˆè¿è¡ŒCell 3ï¼ˆä¿®å¤NumPyå…¼å®¹æ€§ï¼‰\n",
        "2. é‡å¯è¿è¡Œæ—¶ï¼šRuntime -> Restart runtime\n",
        "3. ç„¶åé‡æ–°è¿è¡ŒCell 3å’Œåç»­cells\n",
        "\n",
        "## æ ¸å¿ƒæ€æƒ³\n",
        "\n",
        "1. **Meta-Training (å¤–å¾ªç¯)**: è®­ç»ƒRNNå­¦ä¹ \"å¦‚ä½•å­¦ä¹ \"\n",
        "   - é€šè¿‡å¤§é‡éšæœºä»»åŠ¡ï¼Œè®©RNNå­¦ä¹ å¿«é€Ÿé€‚åº”æ–°ä»»åŠ¡\n",
        "   - RNNé€šè¿‡éšè—çŠ¶æ€é€‚åº”æ–°ä»»åŠ¡ï¼Œè€Œä¸æ”¹å˜æƒé‡Î¸\n",
        "\n",
        "2. **Meta-Testing (å†…å¾ªç¯)**: åœ¨çœŸå®ä»»åŠ¡ä¸Šæµ‹è¯•\n",
        "   - å†»ç»“æƒé‡Î¸_final\n",
        "   - é€šè¿‡1Dæ”¯æŒé›†é€‚åº”ï¼ˆæ¨¡æ‹Ÿäººç±»å­¦ä¹ ï¼‰\n",
        "   - åœ¨2DæŸ¥è¯¢é›†ä¸Šæµ‹è¯•ï¼ˆæ¨¡æ‹Ÿäººç±»æµ‹è¯•ï¼‰\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### ğŸ“¦ åœ¨Colabä¸­å‡†å¤‡é¡¹ç›®æ–‡ä»¶\n",
        "\n",
        "**å¦‚æœè¿™æ˜¯ç¬¬ä¸€æ¬¡åœ¨Colabä¸­è¿è¡Œï¼Œè¯·å…ˆæ‰§è¡Œä»¥ä¸‹æ­¥éª¤ä¹‹ä¸€ï¼š**\n",
        "\n",
        "**é€‰é¡¹1: ä»GitHubå…‹éš†ï¼ˆå¦‚æœé¡¹ç›®åœ¨GitHubä¸Šï¼‰**\n",
        "```python\n",
        "# å–æ¶ˆä¸‹é¢çš„æ³¨é‡Šå¹¶è¿è¡Œ\n",
        "# !git clone https://github.com/your-username/wine-spave.git\n",
        "# %cd wine-spave\n",
        "```\n",
        "\n",
        "**é€‰é¡¹2: ä¸Šä¼ é¡¹ç›®æ–‡ä»¶**\n",
        "- å°†é¡¹ç›®æ–‡ä»¶å¤¹å‹ç¼©ä¸ºzipæ–‡ä»¶\n",
        "- è¿è¡Œä¸‹é¢çš„cellä¸Šä¼ å¹¶è§£å‹\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# å¦‚æœéœ€è¦åœ¨Colabä¸­ä¸Šä¼ é¡¹ç›®æ–‡ä»¶ï¼Œå–æ¶ˆä¸‹é¢çš„æ³¨é‡Šå¹¶è¿è¡Œ\n",
        "# from google.colab import files\n",
        "# import zipfile\n",
        "# import os\n",
        "# \n",
        "# # ä¸Šä¼ zipæ–‡ä»¶\n",
        "# uploaded = files.upload()\n",
        "# \n",
        "# # è§£å‹æ–‡ä»¶\n",
        "# for filename in uploaded.keys():\n",
        "#     if filename.endswith('.zip'):\n",
        "#         with zipfile.ZipFile(filename, 'r') as zip_ref:\n",
        "#             zip_ref.extractall('/content')\n",
        "#         print(f\"âœ“ å·²è§£å‹ {filename}\")\n",
        "#         # åˆ‡æ¢åˆ°é¡¹ç›®ç›®å½•\n",
        "#         project_name = filename.replace('.zip', '')\n",
        "#         if os.path.exists(f'/content/{project_name}'):\n",
        "#             os.chdir(f'/content/{project_name}')\n",
        "#             print(f\"âœ“ å·²åˆ‡æ¢åˆ°é¡¹ç›®ç›®å½•: {os.getcwd()}\")\n",
        "# \n",
        "# print(\"å¦‚æœå·²ä¸Šä¼ é¡¹ç›®ï¼Œè¯·ç»§ç»­è¿è¡Œä¸‹ä¸€ä¸ªcell\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ä¿®å¤Colabä¸­çš„NumPyå…¼å®¹æ€§é—®é¢˜\n",
        "# è¿™ä¸ªcellå¿…é¡»åœ¨å¯¼å…¥torchvisionä¹‹å‰è¿è¡Œ\n",
        "import sys\n",
        "import subprocess\n",
        "\n",
        "# æ£€æŸ¥æ˜¯å¦åœ¨Colabç¯å¢ƒ\n",
        "IN_COLAB = 'google.colab' in sys.modules\n",
        "\n",
        "if IN_COLAB:\n",
        "    print(\"ğŸ”§ ä¿®å¤NumPyç‰ˆæœ¬å…¼å®¹æ€§...\")\n",
        "    try:\n",
        "        import numpy as np\n",
        "        numpy_version = np.__version__\n",
        "        print(f\"å½“å‰NumPyç‰ˆæœ¬: {numpy_version}\")\n",
        "        \n",
        "        # å¦‚æœæ˜¯NumPy 2.xï¼Œéœ€è¦é™çº§åˆ°1.xä»¥å…¼å®¹PyTorch\n",
        "        if numpy_version.startswith('2.'):\n",
        "            print(\"æ£€æµ‹åˆ°NumPy 2.xï¼Œé™çº§åˆ°NumPy 1.26.4ä»¥å…¼å®¹PyTorch...\")\n",
        "            subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", \"--force-reinstall\", \"numpy==1.26.4\"])\n",
        "            # æ¸…é™¤numpyæ¨¡å—ç¼“å­˜\n",
        "            if 'numpy' in sys.modules:\n",
        "                del sys.modules['numpy']\n",
        "            import numpy as np\n",
        "            print(f\"âœ“ NumPyå·²é™çº§åˆ°ç‰ˆæœ¬: {np.__version__}\")\n",
        "        else:\n",
        "            print(f\"âœ“ NumPyç‰ˆæœ¬ {numpy_version} åº”è¯¥å…¼å®¹\")\n",
        "    except Exception as e:\n",
        "        print(f\"æ£€æŸ¥NumPyæ—¶å‡ºé”™: {e}\")\n",
        "        print(\"å®‰è£…NumPy 1.26.4...\")\n",
        "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", \"--force-reinstall\", \"numpy==1.26.4\"])\n",
        "        import numpy as np\n",
        "        print(f\"âœ“ NumPyå®‰è£…å®Œæˆ: {np.__version__}\")\n",
        "    \n",
        "    print(\"âœ“ NumPyå…¼å®¹æ€§æ£€æŸ¥å®Œæˆ\\n\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. ç¯å¢ƒè®¾ç½®å’Œå¯¼å…¥\n",
        "\n",
        "**æ³¨æ„**: å¦‚æœè¿™æ˜¯ç¬¬ä¸€æ¬¡è¿è¡Œï¼Œè¯·å…ˆè¿è¡Œæ­¤cellå®‰è£…ä¾èµ–å¹¶è®¾ç½®ç¯å¢ƒã€‚\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ“ NumPyå·²å®‰è£…\n",
            "âœ“ PyTorchå·²å®‰è£…\n",
            "Matplotlibæœªå®‰è£…ï¼Œæ­£åœ¨å®‰è£…...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ“ Matplotlibå®‰è£…å®Œæˆ\n",
            "\n",
            "é¡¹ç›®æ ¹ç›®å½•: /Users/yifei/Desktop/UCLA/wine-spave\n",
            "\n",
            "å¯¼å…¥é¡¹ç›®æ¨¡å—...\n",
            "âœ“ æ‰€æœ‰æ¨¡å—å¯¼å…¥å®Œæˆ\n"
          ]
        }
      ],
      "source": [
        "# Colabç¯å¢ƒè®¾ç½®\n",
        "import os\n",
        "import sys\n",
        "\n",
        "# æ£€æŸ¥æ˜¯å¦åœ¨Colabç¯å¢ƒ\n",
        "IN_COLAB = 'google.colab' in sys.modules\n",
        "\n",
        "if IN_COLAB:\n",
        "    print(\"ğŸš€ æ£€æµ‹åˆ°Colabç¯å¢ƒ\")\n",
        "    # å®‰è£…å¿…è¦çš„åº“ï¼ˆåœ¨Colabä¸­ä½¿ç”¨!pipæ˜¯æ ‡å‡†åšæ³•ï¼‰\n",
        "    import subprocess\n",
        "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", \"numpy<2\", \"torch\", \"torchvision\", \"matplotlib\"])\n",
        "    \n",
        "    # å…‹éš†æˆ–ä¸Šä¼ é¡¹ç›®ï¼ˆæ ¹æ®å®é™…æƒ…å†µé€‰æ‹©ï¼‰\n",
        "    # æ–¹æ³•1: å¦‚æœé¡¹ç›®åœ¨GitHubä¸Šï¼Œå¯ä»¥å…‹éš†\n",
        "    # import subprocess\n",
        "    # subprocess.check_call(['git', 'clone', 'https://github.com/your-repo/wine-spave.git'])\n",
        "    # os.chdir('wine-spave')\n",
        "    \n",
        "    # æ–¹æ³•2: å¦‚æœé¡¹ç›®éœ€è¦ä¸Šä¼ ï¼Œä½¿ç”¨ä»¥ä¸‹ä»£ç \n",
        "    # from google.colab import files\n",
        "    # uploaded = files.upload()  # ä¸Šä¼ é¡¹ç›®zipæ–‡ä»¶\n",
        "    # import zipfile\n",
        "    # with zipfile.ZipFile('wine-spave.zip', 'r') as zip_ref:\n",
        "    #     zip_ref.extractall('/content')\n",
        "    # os.chdir('/content/wine-spave')\n",
        "    \n",
        "    # æ–¹æ³•3: å¦‚æœé¡¹ç›®å·²ç»åœ¨Colabä¸­ï¼Œç›´æ¥ä½¿ç”¨å½“å‰ç›®å½•\n",
        "    project_root = '/content'  # æˆ–ä½ çš„é¡¹ç›®è·¯å¾„\n",
        "    if os.path.exists('/content') and 'wine-spave' in os.listdir('/content'):\n",
        "        project_root = '/content/wine-spave'\n",
        "        os.chdir(project_root)\n",
        "else:\n",
        "    # æœ¬åœ°ç¯å¢ƒ\n",
        "    import subprocess\n",
        "    current_dir = os.getcwd()\n",
        "    if 'notebooks' in current_dir:\n",
        "        project_root = os.path.dirname(current_dir)\n",
        "    else:\n",
        "        project_root = current_dir\n",
        "    \n",
        "    # æ£€æŸ¥å¹¶å®‰è£…å¿…è¦çš„åº“\n",
        "    try:\n",
        "        import numpy as np\n",
        "        print(\"âœ“ NumPyå·²å®‰è£…\")\n",
        "    except ImportError:\n",
        "        print(\"NumPyæœªå®‰è£…ï¼Œæ­£åœ¨å®‰è£…...\")\n",
        "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", \"numpy<2\"])\n",
        "        import numpy as np\n",
        "        print(\"âœ“ NumPyå®‰è£…å®Œæˆ\")\n",
        "    \n",
        "    try:\n",
        "        import torch\n",
        "        print(\"âœ“ PyTorchå·²å®‰è£…\")\n",
        "    except ImportError:\n",
        "        print(\"PyTorchæœªå®‰è£…ï¼Œæ­£åœ¨å®‰è£…...\")\n",
        "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", \"torch\", \"torchvision\"])\n",
        "        import torch\n",
        "        print(\"âœ“ PyTorchå®‰è£…å®Œæˆ\")\n",
        "    \n",
        "    try:\n",
        "        import matplotlib.pyplot as plt\n",
        "        print(\"âœ“ Matplotlibå·²å®‰è£…\")\n",
        "    except ImportError:\n",
        "        print(\"Matplotlibæœªå®‰è£…ï¼Œæ­£åœ¨å®‰è£…...\")\n",
        "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", \"matplotlib\"])\n",
        "        import matplotlib.pyplot as plt\n",
        "        print(\"âœ“ Matplotlibå®‰è£…å®Œæˆ\")\n",
        "\n",
        "import random\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„\n",
        "if not IN_COLAB:\n",
        "    if project_root not in sys.path:\n",
        "        sys.path.insert(0, project_root)\n",
        "else:\n",
        "    if project_root not in sys.path:\n",
        "        sys.path.insert(0, project_root)\n",
        "\n",
        "print(f\"\\né¡¹ç›®æ ¹ç›®å½•: {project_root}\")\n",
        "\n",
        "# GPUæ£€æµ‹å’Œè®¾ç½®\n",
        "if torch.cuda.is_available():\n",
        "    device = \"cuda\"\n",
        "    print(f\"âœ“ GPUå¯ç”¨: {torch.cuda.get_device_name(0)}\")\n",
        "    print(f\"  GPUæ•°é‡: {torch.cuda.device_count()}\")\n",
        "    print(f\"  å½“å‰GPU: {torch.cuda.current_device()}\")\n",
        "    print(f\"  æ˜¾å­˜: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.2f} GB\")\n",
        "else:\n",
        "    device = \"cpu\"\n",
        "    print(\"âš  GPUä¸å¯ç”¨ï¼Œå°†ä½¿ç”¨CPUï¼ˆé€Ÿåº¦è¾ƒæ…¢ï¼‰\")\n",
        "    if IN_COLAB:\n",
        "        print(\"  æç¤º: åœ¨Colabä¸­ï¼Œè¯·ç¡®ä¿å·²å¯ç”¨GPU: Runtime -> Change runtime type -> GPU\")\n",
        "\n",
        "# å¯¼å…¥é¡¹ç›®æ¨¡å—\n",
        "print(\"\\nå¯¼å…¥é¡¹ç›®æ¨¡å—...\")\n",
        "from data import GridDataGenerator\n",
        "from models import get_model\n",
        "from country_task import get_country_task_loaders\n",
        "from meta_learning import (\n",
        "    meta_train, \n",
        "    meta_test, \n",
        "    create_meta_learning_args,\n",
        "    SequentialRNN\n",
        ")\n",
        "\n",
        "print(\"âœ“ æ‰€æœ‰æ¨¡å—å¯¼å…¥å®Œæˆ\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. å‚æ•°è®¾ç½®\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "å‚æ•°è®¾ç½®å®Œæˆï¼\n",
            "æ¨¡å‹: rnn\n",
            "Metaå­¦ä¹ ç‡: 0.001\n",
            "Supporté›†å¤§å°: 16\n",
            "Queryé›†å¤§å°: 32\n",
            "Metaè¿­ä»£æ¬¡æ•°: 1000\n",
            "æ¯æ‰¹ä»»åŠ¡æ•°: 4\n"
          ]
        }
      ],
      "source": [
        "# åŸºç¡€å‚æ•°ç±»\n",
        "class Args:\n",
        "    def __init__(self):\n",
        "        # è®¾å¤‡è®¾ç½®ï¼ˆè‡ªåŠ¨æ£€æµ‹GPUï¼‰\n",
        "        self.use_cuda = torch.cuda.is_available()\n",
        "        self.device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "        self.seed = 42\n",
        "        \n",
        "        # æ•°æ®é›†è®¾ç½®\n",
        "        self.use_images = False  # ä½¿ç”¨ç´¢å¼•è€Œä¸æ˜¯å›¾åƒ\n",
        "        self.image_dir = 'images/faces16'\n",
        "        self.training_regime = 'ungrouped'\n",
        "        self.grid_size = 4\n",
        "        self.ctx_order = 'first'\n",
        "        self.inner_4x4 = False\n",
        "        \n",
        "        # è®­ç»ƒè®¾ç½®\n",
        "        self.bs = 16  # Batch sizeï¼ˆç”¨äºcountry taskç­‰ï¼‰\n",
        "        \n",
        "        # æ¨¡å‹è®¾ç½®\n",
        "        self.model_name = 'rnn'  # ä½¿ç”¨RNN/LSTM\n",
        "        self.ctx_scale = 1.0\n",
        "        self.measure_grad_norm = False\n",
        "        \n",
        "        # Meta-Learningå‚æ•°\n",
        "        self.meta_lr = 0.001  # Meta-learningå­¦ä¹ ç‡\n",
        "        self.n_support = 16   # æ¯ä¸ªä»»åŠ¡çš„1Dæ”¯æŒæ ·æœ¬æ•°\n",
        "        self.n_query = 32     # æ¯ä¸ªä»»åŠ¡çš„2DæŸ¥è¯¢æ ·æœ¬æ•°\n",
        "        self.n_meta_iterations = 1000  # Meta-trainingè¿­ä»£æ¬¡æ•°ï¼ˆæµ‹è¯•ç”¨ï¼‰\n",
        "        self.n_tasks_per_batch = 4    # æ¯æ‰¹ä»»åŠ¡æ•°\n",
        "\n",
        "# åˆ›å»ºå‚æ•°å¯¹è±¡\n",
        "args = Args()\n",
        "\n",
        "# è®¾ç½®éšæœºç§å­\n",
        "torch.manual_seed(args.seed)\n",
        "random.seed(args.seed)\n",
        "np.random.seed(args.seed)\n",
        "\n",
        "print(\"å‚æ•°è®¾ç½®å®Œæˆï¼\")\n",
        "print(f\"è®¾å¤‡: {args.device} ({'GPUåŠ é€Ÿ' if args.use_cuda else 'CPU'})\")\n",
        "print(f\"æ¨¡å‹: {args.model_name}\")\n",
        "print(f\"Metaå­¦ä¹ ç‡: {args.meta_lr}\")\n",
        "print(f\"Supporté›†å¤§å°: {args.n_support}\")\n",
        "print(f\"Queryé›†å¤§å°: {args.n_query}\")\n",
        "print(f\"Metaè¿­ä»£æ¬¡æ•°: {args.n_meta_iterations}\")\n",
        "print(f\"æ¯æ‰¹ä»»åŠ¡æ•°: {args.n_tasks_per_batch}\")\n",
        "\n",
        "if args.use_cuda:\n",
        "    print(f\"\\nğŸš€ å°†ä½¿ç”¨GPUåŠ é€Ÿè®­ç»ƒï¼ˆé¢„è®¡é€Ÿåº¦æå‡10-100å€ï¼‰\")\n",
        "else:\n",
        "    print(f\"\\nâš  ä½¿ç”¨CPUè®­ç»ƒï¼ˆé€Ÿåº¦è¾ƒæ…¢ï¼Œå»ºè®®åœ¨Colabä¸­å¯ç”¨GPUï¼‰\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. å‡†å¤‡æµ‹è¯•æ•°æ®ï¼ˆCountry Taskï¼‰\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ç”Ÿæˆæµ‹è¯•æ•°æ®...\n",
            "è®­ç»ƒæ ·æœ¬æ•°: 192\n",
            "æµ‹è¯•æ ·æœ¬æ•°: 192\n",
            "\n",
            "âœ“ Country Taskæ•°æ®åˆ›å»ºå®Œæˆ\n",
            "  å›½å®¶æ•°é‡: 8\n",
            "  æ€»æ ·æœ¬æ•°: 256\n",
            "\n",
            "å›½å®¶åˆ—è¡¨:\n",
            "1Då›½å®¶ (4ä¸ª):\n",
            "  0. France: ä¸Šä¸‹æ–‡0 (é«˜æ›´å¥½)\n",
            "  1. Italy: ä¸Šä¸‹æ–‡0 (ä½æ›´å¥½)\n",
            "  2. China: ä¸Šä¸‹æ–‡1 (é«˜æ›´å¥½)\n",
            "  3. Australia: ä¸Šä¸‹æ–‡1 (ä½æ›´å¥½)\n",
            "\n",
            "2Då›½å®¶ (4ä¸ª):\n",
            "  4. Russia: ä¸Šä¸‹æ–‡0(é«˜)+ä¸Šä¸‹æ–‡1(é«˜)\n",
            "  5. Brazil: ä¸Šä¸‹æ–‡0(é«˜)+ä¸Šä¸‹æ–‡1(ä½)\n",
            "  6. India: ä¸Šä¸‹æ–‡0(ä½)+ä¸Šä¸‹æ–‡1(é«˜)\n",
            "  7. Mexico: ä¸Šä¸‹æ–‡0(ä½)+ä¸Šä¸‹æ–‡1(ä½)\n"
          ]
        }
      ],
      "source": [
        "# ç”Ÿæˆgridæ•°æ®ï¼ˆç”¨äºmeta-testingçš„çœŸå®ä»»åŠ¡ï¼‰\n",
        "print(\"ç”Ÿæˆæµ‹è¯•æ•°æ®...\")\n",
        "grid = GridDataGenerator(\n",
        "    training_regime=args.training_regime,\n",
        "    size=args.grid_size,\n",
        "    use_images=args.use_images,\n",
        "    image_dir=args.image_dir,\n",
        "    inner_4x4=args.inner_4x4\n",
        ")\n",
        "\n",
        "print(f\"è®­ç»ƒæ ·æœ¬æ•°: {len(grid.train)}\")\n",
        "print(f\"æµ‹è¯•æ ·æœ¬æ•°: {len(grid.test)}\")\n",
        "\n",
        "# åˆ›å»ºcountry taskæ•°æ®\n",
        "country_loader, country_data_gen = get_country_task_loaders(args, grid)\n",
        "\n",
        "print(f\"\\nâœ“ Country Taskæ•°æ®åˆ›å»ºå®Œæˆ\")\n",
        "print(f\"  å›½å®¶æ•°é‡: {country_data_gen.n_countries}\")\n",
        "print(f\"  æ€»æ ·æœ¬æ•°: {len(country_loader.dataset)}\")\n",
        "\n",
        "# æ˜¾ç¤ºå›½å®¶åˆ—è¡¨\n",
        "print(f\"\\nå›½å®¶åˆ—è¡¨:\")\n",
        "print(\"1Då›½å®¶ (4ä¸ª):\")\n",
        "for i, country_info in enumerate(country_data_gen.countries):\n",
        "    if country_info[1] == 'single':\n",
        "        name = country_info[0]\n",
        "        attrs = country_info[2]\n",
        "        direction = country_info[3]\n",
        "        dir_desc = \"é«˜æ›´å¥½\" if direction == 1 else \"ä½æ›´å¥½\"\n",
        "        print(f\"  {i}. {name}: ä¸Šä¸‹æ–‡{attrs[0]} ({dir_desc})\")\n",
        "\n",
        "print(\"\\n2Då›½å®¶ (4ä¸ª):\")\n",
        "for i, country_info in enumerate(country_data_gen.countries):\n",
        "    if country_info[1] == 'dual':\n",
        "        name = country_info[0]\n",
        "        attrs = country_info[2]\n",
        "        direction = country_info[3]\n",
        "        dir1_desc = \"é«˜\" if direction[0] == 1 else \"ä½\"\n",
        "        dir2_desc = \"é«˜\" if direction[1] == 1 else \"ä½\"\n",
        "        print(f\"  {i}. {name}: ä¸Šä¸‹æ–‡{attrs[0]}({dir1_desc})+ä¸Šä¸‹æ–‡{attrs[1]}({dir2_desc})\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# å¦‚æœæƒ³ä¸´æ—¶ä¿®æ”¹è¿­ä»£æ¬¡æ•°ï¼Œå¯ä»¥åœ¨è¿™é‡Œç›´æ¥ä¿®æ”¹\n",
        "# ä¾‹å¦‚ï¼šåªè®­ç»ƒ500æ¬¡ç”¨äºå¿«é€Ÿæµ‹è¯•\n",
        "args.n_meta_iterations = 500\n",
        "print(f\"âœ“ å·²è®¾ç½®è¿­ä»£æ¬¡æ•°ä¸º: {args.n_meta_iterations}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Meta-Training (å¤–å¾ªç¯)\n",
        "\n",
        "è®­ç»ƒRNNæˆä¸ºä¸€ä¸ª\"å¿«é€Ÿå­¦ä¹ å™¨\"ã€‚è¿™ä¸ªè¿‡ç¨‹ä¼šï¼š\n",
        "- ç”Ÿæˆå¤§é‡éšæœºä»»åŠ¡ï¼ˆæ¯ä¸ªä»»åŠ¡æ˜¯ä¸€ä¸ªæ–°çš„4x4åœ°å›¾ï¼‰\n",
        "- æ¯ä¸ªä»»åŠ¡åŒ…å«1Dæ”¯æŒé›†å’Œ2DæŸ¥è¯¢é›†\n",
        "- RNNé€šè¿‡éšè—çŠ¶æ€é€‚åº”æ¯ä¸ªä»»åŠ¡ï¼Œç„¶ååŸºäºæŸ¥è¯¢é›†çš„è¡¨ç°æ›´æ–°æƒé‡\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "åˆ›å»ºæ¨¡å‹...\n",
            "Model is an LSTM\n",
            "æ¨¡å‹å‚æ•°æ•°é‡: 83778\n",
            "\n",
            "å¼€å§‹Meta-Training...\n",
            "  è¿­ä»£æ¬¡æ•°: 10000\n",
            "  æ¯æ‰¹ä»»åŠ¡æ•°: 4\n",
            "  Supporté›†å¤§å°: 16\n",
            "  Queryé›†å¤§å°: 32\n",
            "\n",
            "æ³¨æ„: è¿™ä¸ªè¿‡ç¨‹å¯èƒ½éœ€è¦è¾ƒé•¿æ—¶é—´\n",
            "      å®é™…ä½¿ç”¨æ—¶ï¼Œå»ºè®®è®¾ç½® n_meta_iterations >= 10000\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# åˆ›å»ºmeta-learningå‚æ•°\n",
        "meta_args = create_meta_learning_args(args)\n",
        "\n",
        "# åˆ›å»ºæ–°æ¨¡å‹ç”¨äºmeta-training\n",
        "print(\"åˆ›å»ºæ¨¡å‹...\")\n",
        "meta_model = get_model(meta_args)\n",
        "meta_model.to(meta_args.device)\n",
        "\n",
        "print(f\"æ¨¡å‹å‚æ•°æ•°é‡: {sum(p.numel() for p in meta_model.parameters()):,}\")\n",
        "print(f\"è®¾å¤‡: {meta_args.device}\")\n",
        "print(f\"\\nå¼€å§‹Meta-Training...\")\n",
        "print(f\"  è¿­ä»£æ¬¡æ•°: {meta_args.n_meta_iterations}\")\n",
        "print(f\"  æ¯æ‰¹ä»»åŠ¡æ•°: {meta_args.n_tasks_per_batch}\")\n",
        "print(f\"  Supporté›†å¤§å°: {meta_args.n_support}\")\n",
        "print(f\"  Queryé›†å¤§å°: {meta_args.n_query}\")\n",
        "\n",
        "if meta_args.use_cuda:\n",
        "    print(f\"\\nğŸš€ ä½¿ç”¨GPUåŠ é€Ÿï¼Œé¢„è®¡è®­ç»ƒæ—¶é—´: {meta_args.n_meta_iterations * 0.1:.1f}ç§’ - {meta_args.n_meta_iterations * 1:.1f}ç§’\")\n",
        "else:\n",
        "    print(f\"\\nâš  ä½¿ç”¨CPUï¼Œé¢„è®¡è®­ç»ƒæ—¶é—´: {meta_args.n_meta_iterations * 5:.1f}ç§’ - {meta_args.n_meta_iterations * 30:.1f}ç§’\")\n",
        "    print(f\"   å»ºè®®åœ¨Colabä¸­å¯ç”¨GPUä»¥åŠ é€Ÿè®­ç»ƒ\")\n",
        "\n",
        "print(f\"\\næ³¨æ„: è¿™ä¸ªè¿‡ç¨‹å¯èƒ½éœ€è¦è¾ƒé•¿æ—¶é—´\")\n",
        "print(f\"      å®é™…ä½¿ç”¨æ—¶ï¼Œå»ºè®®è®¾ç½® n_meta_iterations >= 10000\\n\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "å¼€å§‹Meta-Training...\n",
            "  æ€»è¿­ä»£æ¬¡æ•°: 10000\n",
            "  æ¯æ‰¹ä»»åŠ¡æ•°: 4\n",
            "  Support setå¤§å°: 16\n",
            "  Query setå¤§å°: 32\n",
            "\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# æ‰§è¡Œmeta-training\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m meta_trained_model, meta_losses = \u001b[43mmeta_train\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmeta_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmeta_args\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m    \u001b[49m\u001b[43mn_meta_iterations\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmeta_args\u001b[49m\u001b[43m.\u001b[49m\u001b[43mn_meta_iterations\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m    \u001b[49m\u001b[43mn_tasks_per_batch\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmeta_args\u001b[49m\u001b[43m.\u001b[49m\u001b[43mn_tasks_per_batch\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/UCLA/wine-spave/meta_learning.py:276\u001b[39m, in \u001b[36mmeta_train\u001b[39m\u001b[34m(model, args, n_meta_iterations, n_tasks_per_batch)\u001b[39m\n\u001b[32m    272\u001b[39m query_samples = prepare_samples(task.query_set)\n\u001b[32m    274\u001b[39m \u001b[38;5;66;03m# In-context learning (adaptation): Process support set\u001b[39;00m\n\u001b[32m    275\u001b[39m \u001b[38;5;66;03m# Hidden state evolves but weights Î¸ remain unchanged\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m276\u001b[39m support_outputs, adapted_hidden = \u001b[43mseq_model\u001b[49m\u001b[43m.\u001b[49m\u001b[43mforward_sequence\u001b[49m\u001b[43m(\u001b[49m\u001b[43msupport_samples\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    278\u001b[39m \u001b[38;5;66;03m# In-context testing (evaluation): Process query set with adapted hidden state\u001b[39;00m\n\u001b[32m    279\u001b[39m query_outputs, _ = seq_model.forward_sequence(query_samples, adapted_hidden)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/UCLA/wine-spave/meta_learning.py:169\u001b[39m, in \u001b[36mSequentialRNN.forward_sequence\u001b[39m\u001b[34m(self, samples, hidden_state)\u001b[39m\n\u001b[32m    165\u001b[39m     x = torch.cat([f1_embed, f2_embed, ctx_embed], dim=\u001b[32m0\u001b[39m)  \u001b[38;5;66;03m# [3, batch, state_dim]\u001b[39;00m\n\u001b[32m    167\u001b[39m \u001b[38;5;66;03m# Process through LSTM (maintaining hidden state)\u001b[39;00m\n\u001b[32m    168\u001b[39m \u001b[38;5;66;03m# h_n, c_n: [1, batch, hidden_dim]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m169\u001b[39m lstm_out, (h_n, c_n) = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbase_rnn\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlstm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mh_n\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mc_n\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    171\u001b[39m \u001b[38;5;66;03m# Get output from final hidden state\u001b[39;00m\n\u001b[32m    172\u001b[39m \u001b[38;5;66;03m# h_n: [1, batch, hidden_dim] -> [batch, hidden_dim]\u001b[39;00m\n\u001b[32m    173\u001b[39m output = \u001b[38;5;28mself\u001b[39m.base_rnn.out(h_n.squeeze(\u001b[32m0\u001b[39m))  \u001b[38;5;66;03m# [batch, output_dim]\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/UCLA/wine-spave/.conda/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1509\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1510\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1511\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/UCLA/wine-spave/.conda/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1515\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1516\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1517\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1518\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1519\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1520\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1522\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1523\u001b[39m     result = \u001b[38;5;28;01mNone\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/UCLA/wine-spave/.conda/lib/python3.11/site-packages/torch/nn/modules/rnn.py:878\u001b[39m, in \u001b[36mLSTM.forward\u001b[39m\u001b[34m(self, input, hx)\u001b[39m\n\u001b[32m    875\u001b[39m         hx = \u001b[38;5;28mself\u001b[39m.permute_hidden(hx, sorted_indices)\n\u001b[32m    877\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m batch_sizes \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m878\u001b[39m     result = \u001b[43m_VF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlstm\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_flat_weights\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mnum_layers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    879\u001b[39m \u001b[43m                      \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdropout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbidirectional\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbatch_first\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    880\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    881\u001b[39m     result = _VF.lstm(\u001b[38;5;28minput\u001b[39m, batch_sizes, hx, \u001b[38;5;28mself\u001b[39m._flat_weights, \u001b[38;5;28mself\u001b[39m.bias,\n\u001b[32m    882\u001b[39m                       \u001b[38;5;28mself\u001b[39m.num_layers, \u001b[38;5;28mself\u001b[39m.dropout, \u001b[38;5;28mself\u001b[39m.training, \u001b[38;5;28mself\u001b[39m.bidirectional)\n",
            "\u001b[31mKeyboardInterrupt\u001b[39m: "
          ]
        }
      ],
      "source": [
        "# æ‰§è¡Œmeta-training\n",
        "meta_trained_model, meta_losses = meta_train(\n",
        "    meta_model, \n",
        "    meta_args,\n",
        "    n_meta_iterations=meta_args.n_meta_iterations,\n",
        "    n_tasks_per_batch=meta_args.n_tasks_per_batch\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 4.1 å¯è§†åŒ–Meta-TrainingæŸå¤±\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# å¯è§†åŒ–meta-trainingæŸå¤±\n",
        "plt.figure(figsize=(12, 5))\n",
        "\n",
        "# åŸå§‹æŸå¤±\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(meta_losses, alpha=0.6, linewidth=1)\n",
        "plt.xlabel('Meta-Iteration')\n",
        "plt.ylabel('Meta-Loss')\n",
        "plt.title('Meta-Training Loss (Raw)')\n",
        "plt.grid(True, alpha=0.3)\n",
        "\n",
        "# ç§»åŠ¨å¹³å‡\n",
        "plt.subplot(1, 2, 2)\n",
        "window = min(100, len(meta_losses) // 10)\n",
        "if window > 1 and len(meta_losses) >= window:\n",
        "    moving_avg = np.convolve(meta_losses, np.ones(window)/window, mode='valid')\n",
        "    plt.plot(meta_losses, alpha=0.3, label='Raw', linewidth=1)\n",
        "    plt.plot(range(window-1, len(meta_losses)), moving_avg, \n",
        "             label=f'Moving Average (window={window})', linewidth=2)\n",
        "    plt.xlabel('Meta-Iteration')\n",
        "plt.ylabel('Meta-Loss')\n",
        "plt.title('Meta-Training Loss (Smoothed)')\n",
        "plt.legend()\n",
        "plt.grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(f\"åˆå§‹Meta-Loss: {meta_losses[0]:.4f}\")\n",
        "print(f\"æœ€ç»ˆMeta-Loss: {meta_losses[-1]:.4f}\")\n",
        "if len(meta_losses) > 100:\n",
        "    print(f\"æœ€å100æ¬¡å¹³å‡: {np.mean(meta_losses[-100:]):.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Meta-Testing (å†…å¾ªç¯)\n",
        "\n",
        "åœ¨çœŸå®çš„å›½å®¶ä»»åŠ¡ä¸Šæµ‹è¯•meta-trained RNNï¼š\n",
        "1. å†»ç»“æ¨¡å‹æƒé‡\n",
        "2. å¯¹æ¯ä¸ªå›½å®¶ï¼š\n",
        "   - ä½¿ç”¨1Dæ”¯æŒé›†è¿›è¡Œé€‚åº”ï¼ˆæ¨¡æ‹Ÿäººç±»å­¦ä¹ é˜¶æ®µï¼‰\n",
        "   - åœ¨2DæŸ¥è¯¢é›†ä¸Šæµ‹è¯•ï¼ˆæ¨¡æ‹Ÿäººç±»æµ‹è¯•é˜¶æ®µï¼‰\n",
        "3. æ¯”è¾ƒRNNè¡¨ç°ä¸äººç±»åŸºçº¿\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"å¼€å§‹Meta-Testing...\")\n",
        "print(\"  æ¨¡å‹æƒé‡å·²å†»ç»“\")\n",
        "print(\"  æµ‹è¯•çœŸå®å›½å®¶ä»»åŠ¡\\n\")\n",
        "\n",
        "# æ‰§è¡Œmeta-testing\n",
        "meta_test_results = meta_test(\n",
        "    meta_trained_model,\n",
        "    meta_args,\n",
        "    grid,\n",
        "    country_data_gen,\n",
        "    country_loader\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. ç»“æœåˆ†æ\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"ğŸ“Š Meta-Testing ç»“æœæ€»ç»“\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# æŒ‰å›½å®¶æ˜¾ç¤ºç»“æœ\n",
        "print(\"\\næŒ‰å›½å®¶åˆ†ç±»:\")\n",
        "for country_name, acc in meta_test_results.items():\n",
        "    print(f\"  {country_name:12s}: {acc:.4f} ({acc*100:6.2f}%)\")\n",
        "\n",
        "# è®¡ç®—å¹³å‡å‡†ç¡®ç‡\n",
        "avg_acc = sum(meta_test_results.values()) / len(meta_test_results)\n",
        "print(f\"\\nå¹³å‡å‡†ç¡®ç‡: {avg_acc:.4f} ({avg_acc*100:.2f}%)\")\n",
        "\n",
        "# æŒ‰åå¥½ç±»å‹åˆ†ç±»\n",
        "single_countries = [name for i, name in enumerate(country_data_gen.countries) \n",
        "                   if country_data_gen.countries[i][1] == 'single']\n",
        "dual_countries = [name for i, name in enumerate(country_data_gen.countries) \n",
        "                 if country_data_gen.countries[i][1] == 'dual']\n",
        "\n",
        "single_accs = [meta_test_results[name] for name in single_countries if name in meta_test_results]\n",
        "dual_accs = [meta_test_results[name] for name in dual_countries if name in meta_test_results]\n",
        "\n",
        "if single_accs:\n",
        "    single_avg = sum(single_accs) / len(single_accs)\n",
        "    print(f\"\\n1Då›½å®¶å¹³å‡å‡†ç¡®ç‡: {single_avg:.4f} ({single_avg*100:.2f}%)\")\n",
        "if dual_accs:\n",
        "    dual_avg = sum(dual_accs) / len(dual_accs)\n",
        "    print(f\"2Då›½å®¶å¹³å‡å‡†ç¡®ç‡: {dual_avg:.4f} ({dual_avg*100:.2f}%)\")\n",
        "\n",
        "# åŸºçº¿æ¯”è¾ƒ\n",
        "print(f\"\\nåŸºçº¿æ¯”è¾ƒ:\")\n",
        "print(f\"  éšæœºçŒœæµ‹åŸºçº¿: 33.33% (3é€‰1)\")\n",
        "print(f\"  äººç±»åŸºçº¿: ~66-80% (æ ¹æ®è®ºæ–‡)\")\n",
        "\n",
        "# è¯„ä¼°ç»“æœ\n",
        "print(f\"\\nè¯„ä¼°:\")\n",
        "if avg_acc > 0.66:\n",
        "    print(f\"  âœ“ Meta-LearningæˆåŠŸï¼å‡†ç¡®ç‡({avg_acc*100:.2f}%)è¶…è¿‡äººç±»åŸºçº¿ä¸‹é™\")\n",
        "elif avg_acc > 0.33:\n",
        "    print(f\"  âš  Meta-Learningéƒ¨åˆ†æˆåŠŸï¼Œå‡†ç¡®ç‡({avg_acc*100:.2f}%)è¶…è¿‡éšæœºä½†æœªè¾¾åˆ°äººç±»åŸºçº¿\")\n",
        "else:\n",
        "    print(f\"  âœ— Meta-Learningéœ€è¦è¿›ä¸€æ­¥ä¼˜åŒ–ï¼Œå‡†ç¡®ç‡({avg_acc*100:.2f}%)æ¥è¿‘éšæœºæ°´å¹³\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 6.1 å¯è§†åŒ–ç»“æœ\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# å¯è§†åŒ–meta-testingç»“æœ\n",
        "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
        "\n",
        "# 1. å„å›½å®¶å‡†ç¡®ç‡\n",
        "ax1 = axes[0]\n",
        "country_names = list(meta_test_results.keys())\n",
        "country_accs = list(meta_test_results.values())\n",
        "\n",
        "# æŒ‰ç±»å‹ç€è‰²\n",
        "colors = []\n",
        "for name in country_names:\n",
        "    country_idx = [i for i, c in enumerate(country_data_gen.countries) if c[0] == name][0]\n",
        "    if country_data_gen.countries[country_idx][1] == 'single':\n",
        "        colors.append('#3498db')  # è“è‰²ï¼š1Då›½å®¶\n",
        "    else:\n",
        "        colors.append('#e74c3c')  # çº¢è‰²ï¼š2Då›½å®¶\n",
        "\n",
        "bars = ax1.bar(range(len(country_names)), country_accs, color=colors, alpha=0.7, \n",
        "                edgecolor='black', linewidth=1.5)\n",
        "\n",
        "for i, (bar, acc) in enumerate(zip(bars, country_accs)):\n",
        "    height = bar.get_height()\n",
        "    ax1.text(bar.get_x() + bar.get_width()/2., height,\n",
        "            f'{acc:.2f}',\n",
        "            ha='center', va='bottom', fontsize=10, fontweight='bold')\n",
        "\n",
        "ax1.set_xticks(range(len(country_names)))\n",
        "ax1.set_xticklabels(country_names, rotation=45, ha='right')\n",
        "ax1.set_ylabel('å‡†ç¡®ç‡', fontweight='bold')\n",
        "ax1.set_title('Meta-Testing: å„å›½å®¶å‡†ç¡®ç‡', fontweight='bold', fontsize=12)\n",
        "ax1.set_ylim([0, 1.1])\n",
        "ax1.axhline(y=0.33, color='gray', linestyle='--', alpha=0.5, label='éšæœºçŒœæµ‹ (33%)')\n",
        "ax1.axhline(y=0.66, color='green', linestyle='--', alpha=0.5, label='äººç±»åŸºçº¿ä¸‹é™ (66%)')\n",
        "ax1.legend()\n",
        "ax1.grid(True, alpha=0.3, axis='y')\n",
        "\n",
        "# 2. æŒ‰ç±»å‹åˆ†ç±»\n",
        "ax2 = axes[1]\n",
        "categories = ['æ€»ä½“', '1Då›½å®¶', '2Då›½å®¶']\n",
        "accs = [avg_acc]\n",
        "if single_accs:\n",
        "    accs.append(single_avg)\n",
        "else:\n",
        "    accs.append(0)\n",
        "if dual_accs:\n",
        "    accs.append(dual_avg)\n",
        "else:\n",
        "    accs.append(0)\n",
        "\n",
        "colors_cat = ['#2ecc71', '#3498db', '#e74c3c']\n",
        "bars2 = ax2.bar(categories, accs, color=colors_cat, alpha=0.7, \n",
        "                edgecolor='black', linewidth=1.5)\n",
        "\n",
        "for bar, acc in zip(bars2, accs):\n",
        "    height = bar.get_height()\n",
        "    ax2.text(bar.get_x() + bar.get_width()/2., height,\n",
        "            f'{acc:.3f}\\n({acc*100:.1f}%)',\n",
        "            ha='center', va='bottom', fontweight='bold')\n",
        "\n",
        "ax2.set_ylabel('å‡†ç¡®ç‡', fontweight='bold')\n",
        "ax2.set_title('Meta-Testing: æŒ‰ç±»å‹åˆ†ç±»', fontweight='bold', fontsize=12)\n",
        "ax2.set_ylim([0, 1.1])\n",
        "ax2.axhline(y=0.33, color='gray', linestyle='--', alpha=0.5, label='éšæœºçŒœæµ‹')\n",
        "ax2.axhline(y=0.66, color='green', linestyle='--', alpha=0.5, label='äººç±»åŸºçº¿')\n",
        "ax2.legend()\n",
        "ax2.grid(True, alpha=0.3, axis='y')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"âœ“ å¯è§†åŒ–å®Œæˆ\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. æ€»ç»“\n",
        "\n",
        "### Meta-LearningæˆåŠŸæ ‡å‡†\n",
        "\n",
        "å¦‚æœmeta-learningæˆåŠŸï¼ŒRNNåº”è¯¥èƒ½å¤Ÿï¼š\n",
        "- âœ… åœ¨**ä»æœªè§è¿‡ä»»ä½•2Dè§„åˆ™è®­ç»ƒ**çš„æƒ…å†µä¸‹ï¼ˆé›¶æ ·æœ¬ï¼‰\n",
        "- âœ… åœ¨2Då›½å®¶ä»»åŠ¡ä¸Šè¡¨ç°å‡º**è¿œé«˜äºéšæœºæ°´å¹³**çš„å‡†ç¡®ç‡\n",
        "- âœ… æˆåŠŸæ¨¡æ‹Ÿäººç±»çš„ç»„åˆæ³›åŒ–èƒ½åŠ›\n",
        "\n",
        "### æ€§èƒ½åŸºçº¿\n",
        "- **éšæœºçŒœæµ‹**: 33.33% (3é€‰1)\n",
        "- **äººç±»åŸºçº¿**: ~66-80% (æ ¹æ®è®ºæ–‡)\n",
        "- **ç›®æ ‡**: >66% (è¶…è¿‡äººç±»åŸºçº¿ä¸‹é™)\n",
        "\n",
        "### ä¸‹ä¸€æ­¥\n",
        "1. å¦‚æœå‡†ç¡®ç‡ä½äºé¢„æœŸï¼Œå¯ä»¥å°è¯•ï¼š\n",
        "   - å¢åŠ meta-trainingè¿­ä»£æ¬¡æ•°ï¼ˆâ‰¥10000ï¼‰\n",
        "   - è°ƒæ•´meta-learning rate\n",
        "   - ä¼˜åŒ–support setå’Œquery setçš„å¤§å°\n",
        "   - æ”¹è¿›ä»»åŠ¡ç”Ÿæˆç­–ç•¥\n",
        "\n",
        "2. å¦‚æœå‡†ç¡®ç‡æ»¡è¶³è¦æ±‚ï¼Œå¯ä»¥ï¼š\n",
        "   - è¿›è¡Œæ›´æ·±å…¥çš„åˆ†æ\n",
        "   - ä¸äººç±»æ•°æ®å¯¹æ¯”\n",
        "   - æ¢ç´¢ä¸åŒè¶…å‚æ•°çš„å½±å“\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
